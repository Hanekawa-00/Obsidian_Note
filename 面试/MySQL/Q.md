# 基础
## MySQL性能差的原因
- 为使用索引进行优化
- 查询数据量过多（如全表扫描）
- CPU等硬件资源瓶颈
- SQL语句过于复杂
### Q 
- 使用索引优化
- 添加Redis等缓存
---
## 多表合并查询
1. **Q: 内连接(inner join)和左外连接(left join)有什么区别？举例说明。**
    - **A:** 内连接只返回两个表都匹配的行（交集），左外连接返回左表所有行以及右表匹配的行（左表为主）。举例：查询“哪些客户下过订单”用内连接；查询“所有客户及其订单（即使没下过订单）”用左外连接。
2. **Q: 什么时候用右外连接？它和左外连接能互相转换吗？**
    - **A:** 右外连接以右表为主，返回右表所有行及左表匹配行。例如，查询“所有订单及其对应客户（即使客户不存在）”。左右外连接可以互相转换，只需交换 FROM 和 JOIN 后面的表位置即可。
3. **Q: 交叉连接有什么用？在实际中常用吗？**
    - **A:** 交叉连接返回笛卡尔积，通常不直接用于常规数据查询，因为它结果集巨大。常见用途：生成所有可能的组合（如生成所有商品和所有仓库的组合）、测试数据生成。
4. **Q: 如何优化 JOIN 操作的性能？**
    - **A:**
        - **在连接列上创建索引：** 这是最重要的优化手段。
        - **选择合适的连接类型：** 避免不必要的全表扫描。
        - **优化连接顺序：** 数据库会尝试优化，但有时手动调整 FROM 后面的表顺序（小表在前）可能有效。
        - **减少连接的表数量：** 如果可能，避免连接过多表。
        - **使用小表驱动大表：** 在某些场景下，让结果集较小的表先进行筛选，再与大表连接。
5. **Q: 为什么 MySQL 不直接支持 FULL OUTER JOIN？如何模拟？**
    - **A:** MySQL 早期版本设计如此。模拟方法是使用 LEFT JOIN 和 RIGHT JOIN 的结果集通过 UNION 操作合并。UNION 会自动去重。

![[sql.svg]]
## 三大范式
1. **第一范式 (1NF)：**
    - **原理：** 确保数据库表中的每一列都是 **原子性的**，不可再分。
    - **比喻：** 就像你的 Excel 表格里，一个单元格不能包含多个值。比如，“联系电话”列不能同时写“家里电话: 123, 手机: 456”，而是应该拆分成“家里电话”和“手机”两列，或者更进一步，创建一个单独的“联系方式”表。
    - **要求：** ==每列的值都是不可分割的最小单元。==
    - **示例（不符合 1NF）：** 一个“学生课程成绩”表，其中有一列是“课程列表”，值为“数学, 物理, 英语”。
    - **示例（符合 1NF）：** 将“课程列表”拆分成多行，每行只包含一门课程的信息。
2. **第二范式 (2NF)：**
    - **原理：** 在满足 1NF 的基础上，非主键列必须 **完全依赖于主键**，而不是主键的一部分。
    - **比喻：** 就像你的 Excel 表格，如果你的主键是“学号 + 课程ID”，那么学生的姓名、班级等信息（非主键列）应该只依赖于“学号”（主键的一部分），而不是同时依赖于“学号 + 课程ID”。如果学生姓名依赖于“学号 + 课程ID”，那就意味着同一个学生选不同课时，他的姓名可能会重复存储，且修改名字时需要在多处修改。
    - **要求：** 满足 1NF；非主键列必须完全函数依赖于主键。
    - **示例（不符合 2NF）：** “学生选课成绩”表 (学号, 课程ID, 学生姓名, 课程名称, 成绩)。主键是 (学号, 课程ID)。学生姓名只依赖于学号，课程名称只依赖于课程ID，它们没有完全依赖于联合主键 (学号, 课程ID)。
    - **示例（符合 2NF）：** 将表拆分成三个表：
        - `学生表` (学号, 学生姓名, 班级) - 主键：学号
        - `课程表` (课程ID, 课程名称) - 主键：课程ID
        - `选课成绩表` (学号, 课程ID, 成绩) - 主键：(学号, 课程ID)，外键：学号引用学生表，课程ID引用课程表。 这样，学生姓名只存储在学生表中，课程名称只存储在课程表中，避免了冗余和更新异常。
3. **第三范式 (3NF)：**
    - **原理：** 在满足 2NF 的基础上，非主键列之间 **不能存在传递依赖**(同一个表中存在其他主键依赖)。也就是说，==非主键列不能依赖于另一个非主键列。==
    - **比喻：** 就像你的 Excel 表格，如果你的主键是“学号”，非主键列有“班级编号”和“班主任姓名”。如果班主任姓名只依赖于班级编号（而不是直接依赖于学号），那么就存在传递依赖：学号 -> 班级编号 -> 班主任姓名。这意味着同一个班级的所有学生都会重复存储班主任姓名，且班主任换人时需要在多处修改。
    - **要求：** 满足 2NF；任何非主键列都不对非主键列具有传递依赖。
    - **示例（不符合 3NF）：** 在符合 2NF 的 `学生表` 中 (学号, 学生姓名, 班级编号, 班主任姓名)。主键是学号。班主任姓名依赖于班级编号，班级编号依赖于学号 (学号 -> 班级编号 -> 班主任姓名)。
    - **示例（符合 3NF）：** 将表拆分成两个表：
        - `学生表` (学号, 学生姓名, 班级编号) - 主键：学号，外键：班级编号引用班级表。
        - `班级表` (班级编号, 班主任姓名) - 主键：班级编号。 这样，==班主任姓名只存储在班级表中，避免了冗余和更新异常。==
---
1. **Q: 什么是数据库三大范式？各自解决什么问题？**
    
    - **A:** 范式是数据库设计原则，用于减少冗余和异常。1NF 要求列原子化；2NF 要求非主键完全依赖主键；3NF 要求非主键无传递依赖。分别解决列不可分、部分依赖、传递依赖带来的冗余和异常。
2. **Q: 为什么有时要“反范式”设计？会带来什么问题？**
    
    - **A:** 反范式是为了提高查询性能，通过增加冗余来减少 JOIN 操作。例如，在订单表中存储冗余的客户姓名，查询时无需连接客户表。问题：增加数据冗余、更新异常风险、维护成本高。提示：在面试中，强调“范式与性能的权衡”。
3. **Q: 如何判断一个表是否符合某个范式？**
    
    - **A:** 检查是否满足该范式及之前所有范式的要求。例如，判断是否符合 3NF，先看是否符合 1NF、2NF，再看是否存在传递依赖。
4. **Q: 数据库设计到哪个范式比较合适？**
    
    - **A:** 通常到 3NF 是一个很好的平衡点，既减少了冗余，又不会导致表过多、连接过于复杂。BCNF 更严格，但在一些场景可能引入新的复杂性。
5. **Q: 在实际项目中，你是如何进行数据库设计的？**
    
    - **A:** （结合范式和实际经验回答）先进行需求分析，识别实体和关系 -> 遵循范式原则设计表结构（通常到 3NF）-> 考虑业务场景和性能需求，可能进行适当的反范式优化 -> 定义主键、外键、索引 -> 进行数据库建模和评审。
## IN和EXISTS子查询
>这种查询一般只是判断数据是否存在的查询方法，要得到复杂的数据还是使用`join`合并查询
1. **`IN` 的原理：**
    - **执行过程：** 通常情况下，数据库会==先执行子查询，生成一个结果集列表==（例如，所有下过订单的客户 ID 列表）。然后，数据库遍历外层查询的每一行，检查该行中用于匹配的列值（例如，客户 ID）是否存在于子查询生成的结果集列表中，存在则添加到返回结果中。
    - **实例：** 就像你拿到一份“所有下过订单的客户 ID”的清单（子查询结果集），然后挨个核对“客户名单”上的每一个客户，看看他们的 ID 是否在你的清单上。如果在，就把这个客户的信息挑出来。
    - **特点：** 子查询会执行一次，生成一个完整的列表。适用于子查询结果集较小的情况。
2. **`EXISTS` 的原理：**
    - **执行过程：** `EXISTS` 子查询通常是 **关联子查询**。数据库会==遍历外层查询的每一行。对于外层查询的每一行，都会执行一次子查询。子查询会判断是否存在与当前外层查询行相关联的记录。==只要子查询找到匹配的 **第一行**，就会返回 TRUE，外层查询继续处理下一行；如果子查询遍历完所有相关记录都没有找到匹配的行，就返回 FALSE。
    - **实例：** 就像你拿着“客户名单”上的第一个客户，去“订单列表”里找“这个客户有没有订单”。找到了一个订单？好的，不用再找了，这个客户符合条件，把他挑出来，然后处理下一个客户。如果找遍了都没找到这个客户的订单，就放弃这个客户，处理下一个。
    - **特点：** 子查询会根据外层查询的行数执行多次。适用于子查询结果集较大，或者子查询本身包含复杂的逻辑判断（如 JOIN、WHERE）的情况。
### Q
1. **Q: IN 和 EXISTS 的主要区别是什么？**
    
    - **A:** `IN` 是将外层查询的值与子查询的结果集进行匹配，子查询通常先执行一次；`EXISTS` 是判断子查询是否返回行，子查询通常是关联子查询，对外层查询的每一行执行一次。
2. **Q: 什么时候优先使用 IN，什么时候优先使用 EXISTS？**
    
    - **A:**
        - **IN 优先：** **子查询结果集较小**，或者子查询不依赖外层查询的任何列。
        - **EXISTS 优先：** 子查询结果集较大，或者子查询依赖外层查询的列（关联子查询），且外层查询结果集相对较小。
        - **最准确判断：** 使用 `EXPLAIN` 分析查询计划，看哪种写法的执行计划更优。
3. **Q: EXISTS 后面的 SELECT 1 是什么意思？可以写 SELECT * 吗？**
    
    - **A:** `SELECT 1` 是一种约定俗成的写法，表示“只要找到任何一行就行，具体值是多少不重要”。写 `SELECT *` 也可以，但 `SELECT 1` 效率更高，因为它不需要实际去检索列的值。
4. **Q: IN 和 JOIN 能互相替代吗？有什么优缺点？**
    - **A:** 在很多情况下可以互相替代。
        - **JOIN 优点：** 可以返回两个表中的所有列，更灵活；优化器通常对 JOIN 有更好的优化。
        - **JOIN 缺点：** 在某些场景下，如果只关心是否存在，JOIN 可能会产生冗余的中间结果集，不如 EXISTS 直接。
        - **IN 优点：** 语法简洁，易于理解。
        - **IN 缺点：** 在大数据集上性能可能不如 EXISTS 或优化后的 JOIN。
        - **EXISTS 优点：** 在大数据集上可能性能更好，尤其适合判断是否存在。
        - **EXISTS 缺点：** 只能判断是否存在，不能直接获取子查询中的其他列信息。
5. **Q: IN 子查询中如果返回 NULL 值会有什么影响？**
    - **A:** 如果子查询返回的列表包含 NULL 值，那么 `WHERE column IN (..., NULL, ...)` 这样的条件可能会导致意外的结果。因为 `value IN (..., NULL, ...)` 对于任何非 NULL 的 `value` 都会判断为 UNKNOWN（未知），导致无法匹配。而 `WHERE column NOT IN (..., NULL, ...)` 对于任何值都会判断为 UNKNOWN，导致没有任何行返回。这是一个常见的陷阱。**而 `EXISTS` 子查询通常不受 NULL 值影响。**
## SQL执行顺序
```sql
SELECT DISTINCT column_list
FROM table_name 
[JOIN ...]
WHERE condition
GROUP BY grouping_column(s)
HAVING group_condition
ORDER BY sorting_column(s)
LIMIT limit_value [OFFSET offset_value];
```

1. **`FROM`**: 确定数据来源。首先，确定需要从哪些表获取数据。如果涉及多个表，会进行笛卡尔积操作（虽然优化器通常会避免直接计算完整的笛卡尔积）。
    
2. **`JOIN`**: 表连接。根据 JOIN 条件将 FROM 子句中指定的表连接起来，生成一个更大的中间结果集。
    
3. **`ON`**: JOIN 的连接条件。在 JOIN 过程中，根据 ON 子句指定的条件进行匹配。
    
4. **`WHERE`**: 行过滤。根据 WHERE 子句指定的条件，从 JOIN 生成的中间结果集中筛选出符合条件的行。**注意：** **在这个阶段，SELECT 子句中的列别名是不可用的，因为 SELECT 子句还没执行。(只是构建了语句，或者说是查询逻辑)**
    
5. **`GROUP BY`**: 分组。根据 GROUP BY 子句指定的列，将 WHERE 过滤后的结果集进行分组。
    
6. **`CUBE / ROLLUP` (可选):** 更高级的分组操作，生成更详细的聚合结果。
    
7. **`HAVING`**: 分组后过滤。对 GROUP BY 分组后的结果进行过滤。与 WHERE 不同，HAVING 可以使用聚合函数（如 COUNT(), SUM(), AVG()）作为过滤条件。
    
8. **`SELECT`**: 选择列。根据 SELECT 子句指定的列，从 HAVING 过滤后的结果集中选择需要显示的列。此时，可以在 SELECT 列表中使用列别名。
    
9. **`DISTINCT` (可选):** 去重。如果指定了 DISTINCT，则从 SELECT 选出的结果集中移除重复的行。
    
10. **`ORDER BY`**: 排序。根据 ORDER BY 子句指定的列对最终结果集进行排序。此时，可以使用 SELECT 子句中定义的列别名。
    
11. **`LIMIT / OFFSET` (或 TOP, ROWNUM 等):** 分页。根据 LIMIT 和 OFFSET 子句（或其他数据库系统的等效子句），限制返回的行数，用于实现分页。这个通常是最后执行的步骤。
### 实例

1. 假设我们有 `orders` 表: `order_id`, `user_id`, `order_amount`, `order_date`。
	**需求：** 统计每个用户(`group by user_id`)的订单总金额，只统计 2023 年的订单，并且只显示订单总金额大于 1000 元的用户，最后按总金额降序排列，取前 10 条记录。
```sql
	SELECT user_id, SUM(order_amount) AS total_amount -- 8. SELECT (选择列，可以使用聚合函数和别名)
	FROM orders -- 1. FROM (指定数据来源)
	WHERE order_date >= '2023-01-01' AND order_date < '2024-01-01' -- 4. WHERE (行过滤，发生在分组前)
	GROUP BY user_id -- 5. GROUP BY (按用户分组)
	HAVING SUM(order_amount) > 1000 -- 7. HAVING (分组后过滤，可以使用聚合函数)
	ORDER BY total_amount DESC -- 10. ORDER BY (按总金额降序排序，可以使用 SELECT 中的别名)
	LIMIT 10; -- 11. LIMIT (限制返回行数)
	```
2. **场景：** 社交平台需要找出粉丝数量超过 10000 的用户，并按粉丝数量降序显示前 50 名。
*   **问题：** 需要对用户进行分组（每个用户一组），计算粉丝总数，然后过滤，最后排序和分页。
*   **执行顺序应用：**

    假设有 `followers` 表 (follower_id, followed_user_id)。

    **需求：** 查询粉丝数大于 10000 的用户，并按粉丝数降序排列前 50 名。

    ```sql
    SELECT followed_user_id, COUNT(follower_id) AS follower_count -- 7. SELECT (选择用户ID和粉丝数)
    FROM followers -- 1. FROM (指定数据来源表)
    -- 这里没有 WHERE 子句，因为没有行级别的过滤需求
    GROUP BY followed_user_id -- 5. GROUP BY (按被关注用户分组)
    HAVING COUNT(follower_id) > 10000 -- 6. HAVING (过滤粉丝数大于10000的组)
    ORDER BY follower_count DESC -- 8. ORDER BY (按粉丝数降序排序，使用 SELECT 中的别名)
    LIMIT 50; -- 9. LIMIT (限制返回前50条)
    ```

    **执行流程：**
    1.  从 `followers` 表中获取所有数据。
    2.  将数据按 `followed_user_id` 分组。
    3.  对每个组（每个被关注用户），计算其粉丝数量 (`COUNT(follower_id)`)。
    4.  过滤掉粉丝数量小于等于 10000 的组。
    5.  选择每个符合条件的组的 `followed_user_id` 和计算出的粉丝数量。
    6.  按粉丝数量降序排列结果。
    7.  取出前 50 条记录。

    **效果：** 通过遵循 SQL 的执行顺序，我们能够清晰地表达业务逻辑，并让数据库按照高效的方式执行查询（先分组聚合，再过滤）。
# 数据库架构
## 更新语句执行流程
一条典型的 UPDATE 语句的执行过程涉及多个组件和步骤：
1. **连接器 (Connector):** 客户端与数据库建立连接。
2. **查询缓存 (Query Cache - 8.0 版本后已移除):** 在旧版本中，如果查询语句在缓存中命中，直接返回结果。但对于更新语句，由于会修改数据，缓存通常会失效。
3. **分析器 (Parser):** 对 SQL 语句进行词法分析和语法分析，检查语句是否符合 SQL 语法规范。
4. **优化器 (Optimizer):** 分析 SQL 语句，生成一个最优的执行计划。对于 UPDATE 语句，优化器会决定如何找到需要更新的行（例如，是否使用索引）、以什么顺序进行更新等。
5. **执行器 (Executor):** 根据优化器生成的执行计划，调用存储引擎接口执行具体的更新操作。
6. ==**存储引擎 (Storage Engine - InnoDB):** 负责数据的存储和管理。更新操作最终由存储引擎完成。在 InnoDB 中，更新过程通常涉及以下关键步骤：==
    - **获取锁 (Locking):**
        - 执行器首先会根据 WHERE 条件找到需要更新的行。
        - 为了保证数据的一致性（尤其是在并发环境下），InnoDB 会对这些行加 **排他锁 (X Lock)**。排他锁会阻塞其他事务对这些行的读写操作。
        - 如果==更新语句没有 WHERE 条件，或者 WHERE 条件无法利用索引扫描，可能会进行全表扫描==，并对扫描到的行逐行加锁，甚至在某些情况下加表锁。
        - 如果需要更新的行已经被其他事务加锁，当前事务会进入等待状态，直到获取到锁。
    - **读取数据到内存 (Read Data):** 将需要更新的行从磁盘读取到 InnoDB 的缓冲池 (Buffer Pool) 中。
    - **修改内存中的数据 (Modify Data):** 在缓冲池中修改这些行的数据。
    - **写入 Undo Log (Write Undo Log):** 在修改数据之前，InnoDB 会将==原始数据（旧版本）==写入到 Undo Log 中。Undo Log 用于==事务回滚==。如果事务失败，可以使用 Undo Log 将数据恢复到修改前的状态。
    - **写入 Redo Log Buffer (Write Redo Log Buffer):** 将数据修改的操作（物理操作，记录“在哪个页的哪个偏移量修改了什么值”）写入到 Redo Log Buffer 中。Redo Log 用于==事务持久化和崩溃恢复==。即使数据还没刷到磁盘，只要 Redo Log 记录了，系统崩溃后也能通过 Redo Log 恢复数据。
    - **Redo Log Buffer 刷盘 (Redo Log Buffer Flush):** 根据事务的提交策略（`innodb_flush_log_at_trx_commit` 参数），Redo Log Buffer 中的内容会在事务提交前或提交时被刷写到磁盘的 Redo Log 文件中。这是保证事务持久性的关键步骤。
    - **写入 Binlog (Write Binlog - 如果开启):** 如果数据库开启了二进制日志 (Binlog)，执行器会将在存储引擎层==执行成功的修改操作==（逻辑操作，记录“执行了哪条 SQL 语句”）写入到 Binlog Buffer 中。Binlog 主要用于主从复制和数据恢复。
    - **Binlog Buffer 刷盘 (Binlog Buffer Flush):** Binlog Buffer 中的内容会在事务提交时被刷写到磁盘的 Binlog 文件中。Binlog 的刷盘策略由 `sync_binlog` 参数控制。
    - **提交事务 (Commit Transaction):** 如果一切顺利，事务会被提交。提交操作会标记事务的结束，并释放事务期间持有的锁。在两阶段提交 (Two-Phase Commit - 2PC) 中，Binlog 和 Redo Log 的刷盘顺序和时机会有额外的协调步骤，以保证主从一致性。
    - **脏页刷盘 (Dirty Page Flush):** 在事务提交后，缓冲池中被修改的页面（脏页）会在后台择机刷写到磁盘的数据文件中。这个过程是异步的，不一定在事务提交时立即发生，但 Redo Log 保证了即使在刷盘前系统崩溃，数据也能恢复。
        
## 段区分页
从大到小，InnoDB 存储数据的层级结构可以概览为：表空间 (Tablespace) -> 段 (Segment) -> 区 (Extent) -> 页 (Page) -> 行 (Row)。

1. **行 (Row)**
    
    - **概念**：行是数据库表中的一条记录。它是数据最基本的单位，代表一个独立的实体或事实。InnoDB 采用**行存储方式**，意味着数据是按照行进行组织和管理的。
    - **细节**：行数据可能有不同的格式，例如 COMPACT, REDUNDANT, DYNAMIC 等。MySQL 8.0 默认的行格式是 DYNAMIC。在 InnoDB 中，每条记录（行）会包含一些隐藏列，例如 DB_TRX_ID（记录修改该行的事务 ID）和 DB_ROLL_PTR（指向 Undo Log 中的前一个版本）。如果表没有主键，还会有一个 DB_ROW_ID 用于唯一标识该行。
    - **与索引的关系**：对于 InnoDB 的聚簇索引（也叫主索引），B+ 树的叶子节点直接存储**完整的用户记录**，即行数据。其他辅助索引的叶子节点则存储相应记录的主键值。
2. **页 (Page)**
    
    - **概念**：页是 **InnoDB 存储数据的基本单元**，也是 **磁盘 I/O 的基本单位**。数据库每次读写操作都**至少以 16 KB 为单位**进行。
    - **作用**：引入页的主要目的是**减少磁盘 I/O 次数，提高数据访问效率**。一次读取一个页可以获取多行数据。
    - **细节**：页的标准大小通常是 **16 KB**。在索引结构中，**索引树上的一个节点就是一个页**。B+ 树索引利用了页的物理连续性来实现高效的范围查询和顺序扫描。
    - **与上层的关系**：页组成了更大的单位，称为区。
3. **区 (Extent)**
    
    - **概念**：区是 **一组连续的页**。通常包含 **64 个连续的页**。由于每个页是 16KB，所以一个区的大小是 64 * 16KB = **1MB**。
    - **作用**：使用区而不是单独的页进行数据分配，可以优化磁盘操作，**减少磁盘寻道时间**，特别是在大量数据进行读写时，可以**提高连续空间的分配效率并减少碎片**。它是空间分配的基本单位。
    - **与上层的关系**：区组成了更大的单位，称为段。
4. **段 (Segment)**
    
    - **概念**：段是由一个或多个区组成的。
    - **细节**：常见的段有**数据段、索引段、回滚段**等。
        - **数据段**：用于存储叶子节点中的数据。
        - **索引段**：用于存储非叶子节点的数据（索引页）。
        - **回滚段 (Rollback Segment)**：包含了事务执行过程中用于数据回滚的旧数据（Undo Log）。
    - **与下层的关系**：每个段由一个或多个区组成。
    - **与上层的关系**：表空间由多个段组成。

**层级关系总结**： 表空间 (Tablespace) -> 段 (Segment) -> 区 (Extent) -> 页 (Page) -> 行 (Row) 即：**表空间**包含**段**，**段**包含**区**，**区**包含**页**（通常是 64 个连续的页），**页**包含**行**。

**重要性与关联**：

- **索引原理**：B+ 树索引的节点就是**页**。非叶子节点页存储索引键值和指向下一层页的指针；叶子节点页（对于聚簇索引）存储**完整的行记录**。理解页的概念是理解 B+ 树索引工作方式的基础.
- **磁盘 I/O**：数据库读写操作以**页**为单位。优化器的成本计算会考虑 IO 成本，即从磁盘读取数据到内存的开销，这与需要读取的页数量直接相关。
- **空间管理**：通过以**区**为单位分配和管理空间，InnoDB 提高了效率并减少了碎片。
- **Buffer Pool**：InnoDB 的缓冲池（Buffer Pool）缓存的就是**数据页和索引页**。理解页的概念有助于理解 Buffer Pool 的工作原理。
- **日志和事务**：Redo Log 主要记录物理操作（例如在某个**页**的某个偏移量修改），Undo Log 记录数据修改前的**行**信息。事务和恢复机制与页级别的数据修改密切相关。锁通常作用于**行**或**页**，但底层实现与页结构有关.

通过这些层级结构，InnoDB 能够高效地组织、存储和管理大量数据，并支持复杂的索引、事务和并发控制机制。