# CountDownLatch

## 基本原理回顾

**CountDownLatch** 是Java并发工具，允许线程等待一组操作完成后再继续执行。它维护一个计数器，每完成一个操作就减1，当计数器归零时释放所有等待的线程。

```java
CountDownLatch latch = new CountDownLatch(N); // 初始化计数器为N
latch.countDown(); // 计数器减1
latch.await(); // 等待计数器归零
```
## 场景1：微服务系统启动依赖检查

**问题**：一个微服务启动时需要确认多个外部依赖可用（数据库、Redis、消息队列、配置中心等）才能提供服务。

**面试题**：设计一个系统，确保微服务只有在所有必需的外部服务都可用后才开始处理请求。

**解决方案**：

```java
@Component
public class ServiceHealthChecker {
    private static final Logger logger = LoggerFactory.getLogger(ServiceHealthChecker.class);
    
    @Autowired
    private DataSourceHealthChecker dbChecker;
    
    @Autowired
    private RedisHealthChecker redisChecker;
    
    @Autowired
    private KafkaHealthChecker kafkaChecker;
    
    @Autowired
    private ConfigServerHealthChecker configChecker;
    
    private CountDownLatch startupLatch;
    private volatile boolean systemReady = false;
    
    @PostConstruct
    public void initialize() {
        // 需要检查4个依赖服务
        startupLatch = new CountDownLatch(4);
        
        // 启动检查线程
        checkServiceHealth(dbChecker, "Database");
        checkServiceHealth(redisChecker, "Redis");
        checkServiceHealth(kafkaChecker, "Kafka");
        checkServiceHealth(configChecker, "Config Server");
        
        // 启动等待线程
        new Thread(() -> {
            try {
                // 最多等待2分钟
                boolean allServicesUp = startupLatch.await(2, TimeUnit.MINUTES);
                if (allServicesUp) {
                    systemReady = true;
                    logger.info("All dependent services are available. System is ready to serve requests.");
                } else {
                    logger.error("Timeout waiting for dependent services. Starting in degraded mode.");
                    // 实际可能需要发送告警或根据策略决定是否启动
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                logger.error("Startup process was interrupted", e);
            }
        }, "service-health-waiter").start();
    }
    
    private void checkServiceHealth(HealthChecker checker, String serviceName) {
        new Thread(() -> {
            logger.info("Checking health of: {}", serviceName);
            boolean isHealthy = false;
            
            // 尝试连接，最多尝试10次
            for (int attempt = 1; attempt <= 10; attempt++) {
                try {
                    isHealthy = checker.isServiceHealthy();
                    if (isHealthy) break;
                    
                    logger.warn("{} unavailable, retry attempt {}/10", serviceName, attempt);
                    Thread.sleep(5000); // 等待5秒后重试
                } catch (Exception e) {
                    logger.error("Error checking " + serviceName, e);
                }
            }
            
            if (isHealthy) {
                logger.info("{} is available", serviceName);
            } else {
                logger.error("{} is unavailable after maximum retries", serviceName);
            }
            
            // 无论服务是否就绪，都减少计数
            // 如果服务未就绪，可以记录并在应用中处理降级
            startupLatch.countDown();
        }, serviceName + "-checker").start();
    }
    
    /**
     * API入口点可以使用这个方法决定是否处理请求
     */
    public boolean isSystemReady() {
        return systemReady;
    }
    
    // 健康检查器接口
    public interface HealthChecker {
        boolean isServiceHealthy() throws Exception;
    }
}
```

**实现重点**：
- 使用CountDownLatch确保所有依赖服务检查完成
- 添加超时机制避免永久等待
- 即使某些服务不可用，也要确保countDown()被调用
- 可以根据检查结果实现降级功能

## 场景2：并行API聚合

**问题**：一个页面需要从多个微服务获取数据（如用户信息、订单历史、推荐产品、库存状态）后才能完整展示。

**面试题**：如何设计一个高性能API网关，能够并行调用多个后端服务并聚合结果？

**解决方案**：

```java
@Service
public class ProductDetailAggregator {
    private final ExecutorService executor = Executors.newFixedThreadPool(10);
    
    @Autowired
    private ProductService productService;
    
    @Autowired
    private InventoryService inventoryService;
    
    @Autowired
    private ReviewService reviewService;
    
    @Autowired
    private RecommendationService recommendationService;
    
    public ProductDetailResponse getProductDetails(Long productId) {
        long startTime = System.currentTimeMillis();
        ProductDetailResponse response = new ProductDetailResponse();
        
        // 需要4个服务的数据
        CountDownLatch latch = new CountDownLatch(4);
        AtomicReference<Throwable> errorRef = new AtomicReference<>();
        
        // 1. 获取产品基本信息
        executor.submit(() -> {
            try {
                ProductDto product = productService.getProductById(productId);
                response.setProduct(product);
            } catch (Exception e) {
                errorRef.compareAndSet(null, e);
                // 记录错误但继续处理其他服务
                log.error("Error fetching product info", e);
            } finally {
                latch.countDown();
            }
        });
        
        // 2. 获取库存信息
        executor.submit(() -> {
            try {
                InventoryDto inventory = inventoryService.getInventoryForProduct(productId);
                response.setInventory(inventory);
            } catch (Exception e) {
                log.error("Error fetching inventory info", e);
            } finally {
                latch.countDown();
            }
        });
        
        // 3. 获取评论
        executor.submit(() -> {
            try {
                List<ReviewDto> reviews = reviewService.getTopReviewsForProduct(productId, 5);
                response.setReviews(reviews);
            } catch (Exception e) {
                log.error("Error fetching reviews", e);
            } finally {
                latch.countDown();
            }
        });
        
        // 4. 获取推荐产品
        executor.submit(() -> {
            try {
                List<ProductDto> recommendations = 
                    recommendationService.getRecommendationsForProduct(productId, 4);
                response.setRecommendations(recommendations);
            } catch (Exception e) {
                log.error("Error fetching recommendations", e);
            } finally {
                latch.countDown();
            }
        });
        
        try {
            // 等待所有服务返回，最多等待3秒
            boolean completed = latch.await(3, TimeUnit.SECONDS);
            
            if (!completed) {
                log.warn("Timed out waiting for all services to respond");
                response.setPartialResponse(true);
            }
            
            // 如果产品基本信息获取失败，则返回错误
            if (response.getProduct() == null) {
                throw new ServiceException("Failed to retrieve essential product data");
            }
            
            // 填充响应元数据
            long endTime = System.currentTimeMillis();
            response.setResponseTime(endTime - startTime);
            
            return response;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new ServiceException("Product detail aggregation was interrupted", e);
        }
    }
}
```

**实现重点**：
- 使用CountDownLatch协调多个API调用
- 实现服务降级 - 即使部分服务失败，仍能返回部分结果
- 设置超时以限制总响应时间
- 错误处理和资源清理

## 场景3：大批量数据导入验证

**问题**：系统需要导入大量数据（如百万级用户记录），导入后需要验证数据一致性。

**面试题**：如何设计一个大规模数据导入系统（或者大规模数据迁移等场景下），支持高性能导入后的一致性校验？

**解决方案**：

```java
@Service
public class BulkDataImportService {
    private static final Logger logger = LoggerFactory.getLogger(BulkDataImportService.class);
    
    @Autowired
    private UserRepository userRepository;
    
    @Autowired
    private DataValidator validator;
    
    // 线程池配置
    private final ExecutorService importExecutor = Executors.newFixedThreadPool(10);
    private final ExecutorService validationExecutor = Executors.newFixedThreadPool(5);
    
    public ImportResult importUsersWithValidation(List<UserData> usersToImport) {
        final int totalRecords = usersToImport.size();
        final int batchSize = 5000; // 每批导入5000条
        final int batchCount = (int) Math.ceil((double) totalRecords / batchSize);
        
        // 记录导入过程数据
        AtomicInteger successCount = new AtomicInteger(0);
        AtomicInteger failureCount = new AtomicInteger(0);
        List<String> errors = Collections.synchronizedList(new ArrayList<>());
        Map<Integer, List<Long>> batchToIdsMap = new ConcurrentHashMap<>();
        
        // 第一阶段：并行导入数据
        CountDownLatch importLatch = new CountDownLatch(batchCount);
        
        for (int i = 0; i < batchCount; i++) {
            final int batchIndex = i;
            final int fromIndex = i * batchSize;
            final int toIndex = Math.min(fromIndex + batchSize, totalRecords);
            final List<UserData> batch = usersToImport.subList(fromIndex, toIndex);
            
            importExecutor.submit(() -> {
                List<Long> importedIds = new ArrayList<>();
                try {
                    logger.info("Importing batch {}/{} with {} records", batchIndex + 1, 
                               batchCount, batch.size());
                    
                    for (UserData user : batch) {
                        try {
                            // 前置验证
                            if (!validator.isValidForImport(user)) {
                                failureCount.incrementAndGet();
                                errors.add("Invalid user data: " + user.getEmail());
                                continue;
                            }
                            
                            // 导入数据，获取生成的ID
                            Long id = userRepository.save(user);
                            importedIds.add(id);
                            successCount.incrementAndGet();
                        } catch (Exception e) {
                            failureCount.incrementAndGet();
                            errors.add("Failed to import: " + user.getEmail() + ", reason: " + e.getMessage());
                            logger.error("Error importing user: " + user.getEmail(), e);
                        }
                    }
                    
                    // 记录本批次导入的ID
                    if (!importedIds.isEmpty()) {
                        batchToIdsMap.put(batchIndex, importedIds);
                    }
                    
                    logger.info("Completed batch {}/{}", batchIndex + 1, batchCount);
                } finally {
                    importLatch.countDown();
                }
            });
        }
        
        try {
            // 等待所有导入批次完成
            boolean importCompleted = importLatch.await(30, TimeUnit.MINUTES);
            if (!importCompleted) {
                logger.error("Import timed out after 30 minutes");
                return new ImportResult(successCount.get(), failureCount.get(), 
                                       "Import timeout", errors, false);
            }
            
            logger.info("All batches imported. Starting validation...");
            
            // 第二阶段：验证导入数据的一致性
            if (successCount.get() > 0) {
                CountDownLatch validationLatch = new CountDownLatch(batchToIdsMap.size());
                AtomicBoolean validationSuccess = new AtomicBoolean(true);
                
                for (Map.Entry<Integer, List<Long>> entry : batchToIdsMap.entrySet()) {
                    List<Long> batchIds = entry.getValue();
                    
                    validationExecutor.submit(() -> {
                        try {
	                        // 验证操作
                            logger.info("Validating batch {} with {} records", entry.getKey(), batchIds.size());
                            boolean isValid = validator.validateImportedBatch(batchIds);
                            
                            if (!isValid) {
                                validationSuccess.set(false);
                                errors.add("Validation failed for batch " + entry.getKey());
                            }
                        } catch (Exception e) {// 验证失败时，实际场景下可能做一些回滚操作
                            validationSuccess.set(false);
                            errors.add("Validation error for batch " + entry.getKey() + ": " + e.getMessage());
                            logger.error("Error during validation", e);
                        } finally {// 无论验证是否成功都要减少计数器
                            validationLatch.countDown();
                        }
                    });
                }
                
                // 等待所有验证完成
                boolean validationCompleted = validationLatch.await(15, TimeUnit.MINUTES);
                if (!validationCompleted) {
                    return new ImportResult(successCount.get(), failureCount.get(), 
                                          "Validation timeout", errors, false);
                }
                
                // 如果验证失败，可以触发补偿机制或回滚
                if (!validationSuccess.get()) {
                    logger.error("Validation failed. Consider rollback or compensation.");
                    return new ImportResult(successCount.get(), failureCount.get(), 
                                          "Validation failed", errors, false);
                }
            }
            
            // 一切顺利
            return new ImportResult(successCount.get(), failureCount.get(), 
                                  "Import completed successfully", errors, true);
            
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return new ImportResult(successCount.get(), failureCount.get(), 
                                  "Import was interrupted", errors, false);
        }
    }
    
    // 结果类
    public static class ImportResult {
        private final int successCount;
        private final int failureCount;
        private final String message;
        private final List<String> errors;
        private final boolean successful;
        
        // 构造函数和getter方法省略
        // ...
    }
}
```

**实现重点**：
- 使用**CountDownLatch管理两个阶段（导入和验证）**
- **批处理**设计提高效率和可靠性 (批处理可以减小数据库压力，避免一次性加载到内存中)
- **错误收集和处理机制**（验证失败时可触发回滚或补偿操作（如删除已导入数据），避免脏数据残留。）
- 超时控制避免无限等待
- 一致性验证确保数据完整性

## 场景4：缓存预热机制

**问题**：系统启动时需要预热缓存，加载一些常用数据到内存，以减少冷启动延迟（**避免首次访问时的延迟**）。

**面试题**：设计一个缓存预热器，可以并行加载多种类型的数据到缓存，并在所有数据加载完毕后通知应用程序。

**解决方案**：

```java
@Component
public class CacheWarmupService {
    private static final Logger logger = LoggerFactory.getLogger(CacheWarmupService.class);
    
    @Autowired
    private ProductCacheLoader productLoader;
    
    @Autowired
    private CategoryCacheLoader categoryLoader;
    
    @Autowired
    private PromotionCacheLoader promotionLoader;
    
    @Autowired
    private ConfigurationCacheLoader configLoader;
    
    @Autowired
    private ApplicationEventPublisher eventPublisher;
    
    private ExecutorService executor;
    private volatile boolean warmupComplete = false;
    
    @PostConstruct
    public void initialize() {
        executor = Executors.newFixedThreadPool(4);
    }
    
    @PreDestroy
    public void cleanup() {
        if (executor != null) {
            executor.shutdown();
            try {
                if (!executor.awaitTermination(10, TimeUnit.SECONDS)) {
                    executor.shutdownNow();
                }
            } catch (InterruptedException e) {
                executor.shutdownNow();
                Thread.currentThread().interrupt();
            }
        }
    }
    
    @EventListener(ApplicationReadyEvent.class)
    public void warmupCaches() {
        logger.info("Starting cache warmup process");
        
        // 定义需要预热的缓存及其优先级
        Map<String, CacheLoader<?>> loaders = new LinkedHashMap<>();
        loaders.put("configurations", configLoader);     // 首先加载配置
        loaders.put("categories", categoryLoader);       // 然后加载分类
        loaders.put("promotions", promotionLoader);      // 加载促销信息
        loaders.put("popular-products", productLoader);  // 最后加载热门产品
        
        CountDownLatch warmupLatch = new CountDownLatch(loaders.size());
        Map<String, CacheWarmupStatus> results = new ConcurrentHashMap<>();
        
        // 提交所有预热任务
        for (Map.Entry<String, CacheLoader<?>> entry : loaders.entrySet()) {
            String cacheName = entry.getKey();
            CacheLoader<?> loader = entry.getValue();
            
            executor.submit(() -> {
                long startTime = System.currentTimeMillis();
                logger.info("Starting warmup for cache: {}", cacheName);
                
                try {
                    int itemsLoaded = loader.loadCache();
                    long duration = System.currentTimeMillis() - startTime;
                    
                    results.put(cacheName, new CacheWarmupStatus(true, itemsLoaded, 
                                duration, null));
                    
                    logger.info("Completed warmup for cache: {}. Loaded {} items in {} ms", 
                              cacheName, itemsLoaded, duration);
                    
                } catch (Exception e) {
                    long duration = System.currentTimeMillis() - startTime;
                    results.put(cacheName, new CacheWarmupStatus(false, 0, 
                              duration, e.getMessage()));
                    
                    logger.error("Failed to warmup cache: " + cacheName, e);
                } finally {
                    warmupLatch.countDown();
                }
            });
        }
        
        // 启动监控线程等待所有缓存预热完成
        new Thread(() -> {
            try {
                // 设置最长等待时间
                boolean completed = warmupLatch.await(5, TimeUnit.MINUTES);
                
                if (completed) {
                    logger.info("All caches warmed up successfully");
                    
                    // 检查是否有失败的缓存
                    boolean anyFailures = results.values().stream()
                        .anyMatch(status -> !status.isSuccess());
                    
                    if (anyFailures) {
                        logger.warn("Some caches failed to warm up. System will operate with degraded performance.");
                    }
                } else {
                    logger.error("Cache warmup timed out after 5 minutes");
                }
                
                // 无论如何，标记预热过程已完成
                warmupComplete = true;
                
                // 发布事件通知其他组件缓存预热已完成
                eventPublisher.publishEvent(new CacheWarmupCompletedEvent(this, results));
                
            } catch (InterruptedException e) {
                logger.error("Cache warmup was interrupted", e);
                Thread.currentThread().interrupt();
            }
        }, "cache-warmup-monitor").start();
    }
    
    /**
     * 应用程序可以调用此方法检查缓存是否已预热完成
     */
    public boolean isWarmupComplete() {
        return warmupComplete;
    }
    
    /**
     * 缓存加载器接口
     */
    public interface CacheLoader<T> {
        /**
         * 加载数据到缓存
         * @return 加载的项目数量
         */
        int loadCache() throws Exception;
    }
    
    /**
     * 缓存预热状态类
     */
    @Data
    public static class CacheWarmupStatus {
        private final boolean success;
        private final int itemsLoaded;
        private final long durationMs;
        private final String errorMessage;
    }
    
    /**
     * 缓存预热完成事件
     */
    public static class CacheWarmupCompletedEvent extends ApplicationEvent {
        private final Map<String, CacheWarmupStatus> results;
        
        public CacheWarmupCompletedEvent(Object source, Map<String, CacheWarmupStatus> results) {
            super(source);
            this.results = results;
        }
        
        public Map<String, CacheWarmupStatus> getResults() {
            return results;
        }
    }
}
```

**实现重点**：
- 使用ApplicationReadyEvent触发缓存预热
- 有序加载不同缓存（配置、分类、产品）
- 使用CountDownLatch协调所有预热任务
- 发布ApplicationEvent通知系统其他组件
- 详细记录每个缓存的预热状态

#### 使用CountDownLatch的最佳实践

1. **设置超时机制**：生产环境中总是使用`await(timeout, unit)`，避免永久阻塞
2. **正确计数**：确保计数器值与实际任务数匹配
3. **异常处理**：在`finally`块中调用`countDown()`确保计数器正确减少
4. **资源清理**：正确关闭线程池
5. **替代方案考虑**：对于简单场景，考虑CompletableFuture

# CyclicBarrier 实战指南

#### 基本原理

**CyclicBarrier** 是 Java 并发编程中的同步工具，允许多个线程在某个公共屏障点互相等待。与 CountDownLatch 不同，CyclicBarrier 具有可重用性，当所有线程都到达屏障点后，屏障会重置，允许线程集合再次使用它。

```java
CyclicBarrier barrier = new CyclicBarrier(N); // 创建一个可容纳N个线程的屏障
barrier.await(); // 线程到达屏障点，等待其他线程
```

关键特性：

- 可以设置到达屏障点后自动执行的操作（barriers action）
- 支持超时等待
- 可以被重置和重用
- 提供到达屏障点的线程数量查询功能

#### 开发中的真实应用场景

## 场景1：分布式计算中的迭代计算

**问题**：开发一个并行迭代算法，每个迭代步骤需要所有工作线程完成当前迭代后才能进入下一轮迭代。
**面试题**：如何实现一个高效的并行迭代计算框架，确保每次迭代的数据一致性？**解决方案**：

```java
@Service
public class ParallelMatrixProcessor {
    private static final Logger logger = LoggerFactory.getLogger(ParallelMatrixProcessor.class);
    
    public double[][] processLargeMatrix(double[][] initialMatrix, int iterations) {
        int rows = initialMatrix.length;
        int cols = initialMatrix[0].length;
        
        // 创建工作线程池
        int threadCount = Runtime.getRuntime().availableProcessors();
        ExecutorService executor = Executors.newFixedThreadPool(threadCount);
        
        // 为每次迭代后的可能的同步操作创建屏障
        CyclicBarrier iterationBarrier = new CyclicBarrier(threadCount, () -> {
            // 这是屏障动作，当所有线程到达屏障时执行
            logger.info("All threads completed current iteration. Calculating global metrics...");
            // 在这里可以执行全局计算，如收敛检查
        });
        
        // 为输出结果准备两个矩阵（双缓冲）
        double[][] currentMatrix = deepCopy(initialMatrix);
        double[][] nextMatrix = new double[rows][cols];
        
        try {
            // 为每个工作线程分配行
            int rowsPerThread = rows / threadCount;
            List<Future<?>> futures = new ArrayList<>();
            
            for (int t = 0; t < threadCount; t++) {
                final int threadIndex = t;
                final int startRow = t * rowsPerThread;
                final int endRow = (t == threadCount - 1) ? rows : startRow + rowsPerThread;
                
                futures.add(executor.submit(() -> {
                    try {
                        logger.info("Thread {} processing rows {}-{}", 
                                  threadIndex, startRow, endRow - 1);
                        
                        for (int iter = 0; iter < iterations; iter++) {
                            // 处理矩阵分区
                            for (int i = startRow; i < endRow; i++) {
                                for (int j = 0; j < cols; j++) {
                                    // 示例计算：平均周围单元格的值
                                    nextMatrix[i][j] = calculateNewValue(currentMatrix, i, j, rows, cols);
                                }
                            }
                            
                            // 等待所有线程完成当前迭代
                            try {
                                iterationBarrier.await();
                            } catch (BrokenBarrierException e) {
                                logger.error("Barrier broken in thread " + threadIndex, e);
                                return;
                            }
                            
                            // 所有线程已到达屏障，现在我们可以交换矩阵引用以准备下一次迭代
                            if (threadIndex == 0) { // 只让一个线程执行交换操作
                                synchronized (ParallelMatrixProcessor.class) {
                                    double[][] temp = currentMatrix;
                                    currentMatrix = nextMatrix;
                                    nextMatrix = temp;
                                    logger.info("Completed iteration {}/{}", iter + 1, iterations);
                                }
                            }
                            
                            // 等待矩阵交换完成
                            try {
                                iterationBarrier.await();
                            } catch (BrokenBarrierException e) {
                                logger.error("Barrier broken during matrix swap in thread " + threadIndex, e);
                                return;
                            }
                        }
                        
                        logger.info("Thread {} completed all iterations", threadIndex);
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                        logger.error("Thread " + threadIndex + " was interrupted", e);
                    }
                }));
            }
            
            // 等待所有工作线程完成
            for (Future<?> future : futures) {
                future.get();
            }
            
            return currentMatrix; // 返回最终结果
            
        } catch (Exception e) {
            logger.error("Error during parallel processing", e);
            throw new RuntimeException("Matrix processing failed", e);
        } finally {
            executor.shutdown();
        }
    }
    
    private double calculateNewValue(double[][] matrix, int row, int col, int maxRow, int maxCol) {
        // 计算周围单元格的平均值（示例算法）
        double sum = 0;
        int count = 0;
        
        for (int i = Math.max(0, row - 1); i <= Math.min(maxRow - 1, row + 1); i++) {
            for (int j = Math.max(0, col - 1); j <= Math.min(maxCol - 1, col + 1); j++) {
                sum += matrix[i][j];
                count++;
            }
        }
        
        return sum / count;
    }
    
    private double[][] deepCopy(double[][] matrix) {
        return Arrays.stream(matrix)
                .map(double[]::clone)
                .toArray(double[][]::new);
    }
}
```

**实现重点**：

- 使用CyclicBarrier同步每次迭代，确保所有线程完成当前迭代后再进入下一轮
- 利用屏障动作（barrier action）在每次迭代结束后执行全局操作
- 双重屏障确保矩阵交换安全完成
- 动态分配工作负载以平衡处理

## 场景2：高性能游戏服务器的回合制系统

**问题**：在一个多人在线游戏中，需要实现回合制游戏逻辑，每回合所有玩家必须提交行动，才能进入下一回合。**面试题**：如何设计一个能支持成千上万玩家同时在线的回合制游戏服务器架构？**解决方案**：

```java
@Service
public class TurnBasedGameEngine {
    private static final Logger logger = LoggerFactory.getLogger(TurnBasedGameEngine.class);

    @Autowired
    private GameStateRepository gameStateRepo;
    
    @Autowired
    private PlayerActionService actionService;
    
    @Autowired
    private GameRulesEngine rulesEngine;
    
    // 游戏房间状态映射
    private final ConcurrentHashMap<String, GameRoom> activeRooms = new ConcurrentHashMap<>();
    
    /**
     * 创建一个新的游戏房间
     */
    public GameRoom createRoom(String roomId, int playerCount, int turnTimeoutSeconds) {
        GameRoom room = new GameRoom(roomId, playerCount, turnTimeoutSeconds);
        activeRooms.put(roomId, room);
        return room;
    }
    
    /**
     * 玩家加入房间
     */
    public void joinRoom(String roomId, String playerId) {
        GameRoom room = activeRooms.get(roomId);
        if (room != null) {
            room.addPlayer(playerId);
        } else {
            throw new IllegalArgumentException("Room not found: " + roomId);
        }
    }
    
    /**
     * 玩家提交回合动作
     */
    public void submitAction(String roomId, String playerId, PlayerAction action) {
        GameRoom room = activeRooms.get(roomId);
        if (room != null) {
            room.submitAction(playerId, action);
        } else {
            throw new IllegalArgumentException("Room not found: " + roomId);
        }
    }
    
    /**
     * 代表一个游戏房间及其状态
     */
    public class GameRoom {
        private final String roomId;
        private final int maxPlayers;
        private final Set<String> joinedPlayers = ConcurrentHashMap.newKeySet();
        private final Map<String, PlayerAction> currentTurnActions = new ConcurrentHashMap<>();
        private final int turnTimeoutSeconds;
        
        private volatile CyclicBarrier turnBarrier;
        private volatile int currentTurn = 0;
        private volatile boolean gameStarted = false;
        private volatile boolean gameEnded = false;
        
        private ScheduledExecutorService scheduler;
        private ScheduledFuture<?> turnTimeoutTask;
        
        public GameRoom(String roomId, int maxPlayers, int turnTimeoutSeconds) {
            this.roomId = roomId;
            this.maxPlayers = maxPlayers;
            this.turnTimeoutSeconds = turnTimeoutSeconds;
            
            // 创建一个初始屏障，仅用于等待玩家加入
            this.turnBarrier = new CyclicBarrier(maxPlayers, this::processTurn);
            
            // 初始化调度器
            this.scheduler = Executors.newScheduledThreadPool(1);
        }
        
        /**
         * 添加玩家到房间
         */
        public synchronized void addPlayer(String playerId) {
            if (gameStarted) {
                throw new IllegalStateException("Game already started");
            }
            
            if (joinedPlayers.size() >= maxPlayers) {
                throw new IllegalStateException("Room is full");
            }
            
            joinedPlayers.add(playerId);
            logger.info("Player {} joined room {}. {}/{} players", 
                      playerId, roomId, joinedPlayers.size(), maxPlayers);
            
            // 如果所有玩家都加入了，启动游戏
            if (joinedPlayers.size() == maxPlayers) {
                startGame();
            }
        }
        
        /**
         * 开始游戏
         */
        private void startGame() {
            logger.info("Starting game in room {}. All {} players joined.", roomId, maxPlayers);
            gameStarted = true;
            currentTurn = 1;
            
            // 初始化游戏状态
            GameState initialState = rulesEngine.createInitialState(roomId, joinedPlayers);
            gameStateRepo.saveState(roomId, initialState);
            
            // 开始第一回合，设置超时
            scheduleTurnTimeout();
        }
        
        /**
         * 设置回合超时
         */
        private void scheduleTurnTimeout() {
            if (turnTimeoutTask != null) {
                turnTimeoutTask.cancel(false);
            }
            
            turnTimeoutTask = scheduler.schedule(() -> {
                logger.warn("Turn {} timed out in room {}", currentTurn, roomId);
                
                // 处理未提交动作的玩家
                Set<String> missingPlayers = new HashSet<>(joinedPlayers);
                missingPlayers.removeAll(currentTurnActions.keySet());
                
                // 为未行动的玩家提供默认动作
                for (String playerId : missingPlayers) {
                    PlayerAction defaultAction = rulesEngine.createDefaultAction(playerId);
                    submitAction(playerId, defaultAction);
                    logger.info("Generated default action for inactive player {} in room {}", 
                              playerId, roomId);
                }
            }, turnTimeoutSeconds, TimeUnit.SECONDS);
        }
        
        /**
         * 提交玩家回合动作
         */
        public void submitAction(String playerId, PlayerAction action) {
            if (!gameStarted || gameEnded) {
                throw new IllegalStateException(
                    "Cannot submit action: game not active in room " + roomId);
            }
            
            if (!joinedPlayers.contains(playerId)) {
                throw new IllegalArgumentException("Player not in this room: " + playerId);
            }
            
            // 记录玩家动作
            currentTurnActions.put(playerId, action);
            logger.info("Player {} submitted action for turn {} in room {}", 
                      playerId, currentTurn, roomId);
            
            // 尝试推进回合
            tryAdvanceTurn();
        }
        
        /**
         * 尝试推进回合
         */
        private synchronized void tryAdvanceTurn() {
            // 检查是否所有玩家都提交了动作
            if (currentTurnActions.size() == joinedPlayers.size()) {
                // 取消回合超时
                if (turnTimeoutTask != null) {
                    turnTimeoutTask.cancel(false);
                }
                
                // 处理回合
                processTurn();
            }
        }
        
        /**
         * 处理回合
         */
        private void processTurn() {
            logger.info("Processing turn {} in room {}", currentTurn, roomId);
            
            try {
                // 获取当前游戏状态
                GameState currentState = gameStateRepo.getState(roomId);
                
                // 应用所有玩家行动到游戏状态
                GameState nextState = rulesEngine.applyActions(currentState, currentTurnActions);
                
                // 保存新状态
                gameStateRepo.saveState(roomId, nextState);
                
                // 检查游戏是否结束
                if (rulesEngine.isGameOver(nextState)) {
                    endGame(nextState);
                    return;
                }
                
                // 准备下一回合
                currentTurn++;
                currentTurnActions.clear();
                
                // 通知玩家新回合开始
                for (String playerId : joinedPlayers) {
                    actionService.notifyTurnStart(playerId, roomId, currentTurn, 
                                               nextState.getPlayerView(playerId));
                }
                
                // 设置下一回合超时
                scheduleTurnTimeout();
                
            } catch (Exception e) {
                logger.error("Error processing turn " + currentTurn + " in room " + roomId, e);
                // 可以实现错误恢复逻辑
            }
        }
        
        /**
         * 结束游戏
         */
        private void endGame(GameState finalState) {
            logger.info("Game ended in room {} after {} turns", roomId, currentTurn);
            gameEnded = true;
            
            if (turnTimeoutTask != null) {
                turnTimeoutTask.cancel(false);
            }
            
            // 清理资源
            scheduler.shutdown();
            
            // 通知所有玩家游戏结束
            Map<String, Integer> scores = rulesEngine.calculateFinalScores(finalState);
            for (String playerId : joinedPlayers) {
                actionService.notifyGameEnd(playerId, roomId, scores, 
                                         finalState.getPlayerView(playerId));
            }
            
            // 从活动房间中移除
            activeRooms.remove(roomId);
        }
    }
    
    // 游戏相关类的接口定义
    public interface GameState {
        PlayerView getPlayerView(String playerId);
    }
    
    public interface PlayerView {
        // 玩家视角数据
    }
    
    public interface PlayerAction {
        // 玩家行动数据
    }
}
```

**实现重点**：

- 利用CyclicBarrier提供回合同步
- 超时处理确保游戏不会因玩家掉线而卡住
- 异步通知机制通知玩家回合状态
- 游戏状态的原子更新和一致性保障

## 场景3：并行图像处理流水线

**问题**：开发一个大规模图像处理系统，需要对大量图像进行多阶段处理，确保每个阶段都完成才能进入下一阶段。**面试题**：如何设计一个高性能的并行图像处理流水线，能同时处理成批的图像？**解决方案**：

```java
@Service
public class ParallelImageProcessor {
    private static final Logger logger = LoggerFactory.getLogger(ParallelImageProcessor.class);
    
    @Value("${image.processing.thread-count:8}")
    private int processingThreads;
    
    @Value("${image.batch.size:50}")
    private int batchSize;
    
    @Autowired
    private ImageLoaderService imageLoader;
    
    @Autowired
    private ColorCorrectionService colorCorrection;
    
    @Autowired
    private NoiseReductionService noiseReduction;
    
    @Autowired
    private EdgeDetectionService edgeDetection;
    
    @Autowired
    private WatermarkService watermark;
    
    @Autowired
    private ImageCompressorService compressor;
    
    @Autowired
    private ImageStoreService imageStore;
    
    /**
     * 批量处理图像
     */
    public List<ProcessedImage> processBatch(List<String> imageIds) {
        int imagesToProcess = imageIds.size();
        
        // 创建处理线程池
        ExecutorService executor = Executors.newFixedThreadPool(processingThreads);
        
        try {
            // 分配每个线程处理的图像
            int imagesPerThread = (int) Math.ceil((double) imagesToProcess / processingThreads);
            List<List<String>> threadWorkloads = new ArrayList<>();
            
            for (int i = 0; i < processingThreads; i++) {
                int fromIndex = i * imagesPerThread;
                if (fromIndex >= imagesToProcess) {
                    break;
                }
                
                int toIndex = Math.min(fromIndex + imagesPerThread, imagesToProcess);
                threadWorkloads.add(imageIds.subList(fromIndex, toIndex));
            }
            
            int activeThreads = threadWorkloads.size();
            
            // 创建处理流水线屏障点，每个阶段所有线程都必须完成才能进入下一阶段
            CyclicBarrier loadingBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("All images loaded successfully"));
                
            CyclicBarrier colorBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("Color correction completed for all images"));
                
            CyclicBarrier noiseBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("Noise reduction completed for all images"));
                
            CyclicBarrier edgeBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("Edge detection completed for all images"));
                
            CyclicBarrier watermarkBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("Watermarks applied to all images"));
                
            CyclicBarrier compressionBarrier = new CyclicBarrier(activeThreads, 
                () -> logger.info("All images compressed"));
            
            // 创建共享结果集
            final List<ProcessedImage> results = Collections.synchronizedList(new ArrayList<>());
            List<Future<?>> futures = new ArrayList<>();
            AtomicInteger successCount = new AtomicInteger(0);
            
            // 启动工作线程
            for (int threadIdx = 0; threadIdx < activeThreads; threadIdx++) {
                final List<String> threadImages = threadWorkloads.get(threadIdx);
                final int threadId = threadIdx;
                
                futures.add(executor.submit(() -> {
                    try {
                        List<ImageData> threadImageData = new ArrayList<>(threadImages.size());
                        
                        // 阶段1: 加载图像
                        logger.info("Thread {} loading {} images", threadId, threadImages.size());
                        for (String imageId : threadImages) {
                            try {
                                ImageData img = imageLoader.loadImage(imageId);
                                threadImageData.add(img);
                            } catch (Exception e) {
                                logger.error("Failed to load image " + imageId, e);
                                // 创建占位图像保持索引一致性
                                threadImageData.add(null);
                            }
                        }
                        
                        // 同步点：图像加载
                        syncAtBarrier(loadingBarrier, "image loading", threadId);
                        
                        // 阶段2: 颜色校正
                        logger.info("Thread {} starting color correction", threadId);
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    colorCorrection.process(img);
                                } catch (Exception e) {
                                    logger.error("Color correction failed for image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        // 同步点：颜色校正
                        syncAtBarrier(colorBarrier, "color correction", threadId);
                        
                        // 阶段3: 降噪
                        logger.info("Thread {} starting noise reduction", threadId);
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    noiseReduction.process(img);
                                } catch (Exception e) {
                                    logger.error("Noise reduction failed for image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        // 同步点：降噪
                        syncAtBarrier(noiseBarrier, "noise reduction", threadId);
                        
                        // 阶段4: 边缘检测
                        logger.info("Thread {} starting edge detection", threadId);
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    edgeDetection.process(img);
                                } catch (Exception e) {
                                    logger.error("Edge detection failed for image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        // 同步点：边缘检测
                        syncAtBarrier(edgeBarrier, "edge detection", threadId);
                        
                        // 阶段5: 水印
                        logger.info("Thread {} applying watermarks", threadId);
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    watermark.apply(img);
                                } catch (Exception e) {
                                    logger.error("Watermarking failed for image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        // 同步点：水印
                        syncAtBarrier(watermarkBarrier, "watermarking", threadId);
                        
                        // 阶段6: 压缩
                        logger.info("Thread {} compressing images", threadId);
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    compressor.compress(img);
                                } catch (Exception e) {
                                    logger.error("Compression failed for image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        // 同步点：压缩
                        syncAtBarrier(compressionBarrier, "compression", threadId);
                        
                        // 保存处理后的图像
                        for (int i = 0; i < threadImageData.size(); i++) {
                            ImageData img = threadImageData.get(i);
                            if (img != null) {
                                try {
                                    String originalId = threadImages.get(i);
                                    String processedUrl = imageStore.saveProcessedImage(img);
                                    results.add(new ProcessedImage(originalId, processedUrl));
                                    successCount.incrementAndGet();
                                } catch (Exception e) {
                                    logger.error("Failed to save processed image " + 
                                              threadImages.get(i), e);
                                }
                            }
                        }
                        
                        logger.info("Thread {} completed processing all images", threadId);
                    } catch (Exception e) {
                        logger.error("Thread " + threadId + " encountered an error", e);
                    }
                }));
            }
            
            // 等待所有线程完成
            for (Future<?> future : futures) {
                future.get();
            }
            
            logger.info("Batch processing completed. Successfully processed {}/{} images", 
                      successCount.get(), imagesToProcess);
            
            return results;
            
        } catch (Exception e) {
            logger.error("Error during batch image processing", e);
            throw new RuntimeException("Image processing failed", e);
        } finally {
            executor.shutdown();
        }
    }
    
    /**
     * 辅助方法：在屏障点同步并处理可能的异常
     */
    private void syncAtBarrier(CyclicBarrier barrier, String stageName, int threadId) {
        try {
            barrier.await(3, TimeUnit.MINUTES);
        } catch (InterruptedException e) {
            logger.error("Thread " + threadId + " was interrupted during " + stageName, e);
            Thread.currentThread().interrupt();
        } catch (BrokenBarrierException e) {
            logger.error("Barrier was broken during " + stageName + " in thread " + threadId, e);
        } catch (TimeoutException e) {
            logger.error("Timeout waiting at barrier during " + stageName + " in thread " + threadId, e);
        }
    }
    
    /**
     * 处理后的图像信息
     */
    @Data
    @AllArgsConstructor
    public static class ProcessedImage {
        private String originalId;
        private String processedUrl;
    }
    
    /**
     * 图像数据接口
     */
    public interface ImageData {
        // 图像数据结构
    }
}
```

**实现重点**：

- 使用多个CyclicBarrier同步处理流水线的每个阶段
- 每个阶段都有独立的错误处理和日志记录
- 超时处理确保流程不会永久阻塞
- 通过屏障动作汇总和记录处理进度

## 场景4：ETL数据仓库加载流程

**问题**：开发一个ETL（提取、转换、加载）系统，需要同步多个数据源到数据仓库，其中某些步骤需要协调所有数据源。
**面试题**：如何设计一个高效的ETL流程，能够处理不同数据源的依赖关系，并在出错时提供恢复机制？**解决方案**：

```java
@Service
public class DataWarehouseETLProcessor {
    private static final Logger logger = LoggerFactory.getLogger(DataWarehouseETLProcessor.class);
    
    @Autowired
    private List<DataSourceExtractor> dataSourceExtractors;
    
    @Autowired
    private DataTransformer transformer;
    
    @Autowired
    private DataWarehouseLoader loader;
    
    @Autowired
    private DataConsistencyValidator validator;
    
    @Autowired
    private ETLMetricsCollector metrics;
    
    /**
     * 执行完整的ETL流程
     */
    public ETLResult performETL(ETLRequest request) {
        long startTime = System.currentTimeMillis();
        logger.info("Starting ETL process for request: {}", request.getJobId());
        
        int dataSourceCount = dataSourceExtractors.size();
        ExecutorService executor = Executors.newFixedThreadPool(dataSourceCount);
        
        // 用于记录处理结果的数据结构
        Map<String, ExtractedData> extractedDataMap = new ConcurrentHashMap<>();
        Map<String, TransformedData> transformedDataMap = new ConcurrentHashMap<>();
        AtomicBoolean etlSuccess = new AtomicBoolean(true);
        
        try {
            // 创建各个ETL阶段的同步点
            CyclicBarrier extractionBarrier = new CyclicBarrier(dataSourceCount, 
                () -> logger.info("All data sources extracted"));
                
            CyclicBarrier transformationBarrier = new CyclicBarrier(dataSourceCount, 
                () -> logger.info("All data transformation completed"));
                
            CyclicBarrier validationBarrier = new CyclicBarrier(dataSourceCount, () -> {
                logger.info("Starting global validation across all data sources");
                try {
                    // 在所有数据转换完成后执行全局验证
                    boolean valid = validator.validateGlobalConsistency(transformedDataMap);
                    if (!valid) {
                        logger.error("Global data consistency validation failed!");
                        etlSuccess.set(false);
                    } else {
                        logger.info("Global data consistency validation passed");
                    }
                } catch (Exception e) {
                    logger.error("Error during global validation", e);
                    etlSuccess.set(false);
                }
            });
            
            CyclicBarrier loadBarrier = new CyclicBarrier(dataSourceCount, 
                () -> logger.info("All data loaded to data warehouse"));
            
            // 记录各个数据源的处理结果
            List<ETLSourceResult> sourceResults = Collections.synchronizedList(new ArrayList<>());
            List<Future<?>> futures = new ArrayList<>();
            
            // 启动每个数据源的处理
            for (int i = 0; i < dataSourceCount; i++) {
                final DataSourceExtractor extractor = dataSourceExtractors.get(i);
                final String sourceId = extractor.getSourceId();
                
                futures.add(executor.submit(() -> {
                    ETLSourceResult result = new ETLSourceResult(sourceId);
                    result.setStartTime(System.currentTimeMillis());
                    
                    try {
                        // 步骤1: 提取阶段
                        logger.info("Starting extraction from source: {}", sourceId);
                        ExtractedData extractedData = null;
                        try {
                            extractedData = extractor.extractData(request);
                            extractedDataMap.put(sourceId, extractedData);
                            result.setRecordsExtracted(extractedData.getRecordCount());
                            result.setExtractionSuccess(true);
                            logger.info("Extracted {} records from {}", 
                                      extractedData.getRecordCount(), sourceId);
                            
                            // 收集提取指标
                            metrics.recordExtraction(sourceId, extractedData.getRecordCount());
                        } catch (Exception e) {
                            logger.error("Extraction failed for source: " + sourceId, e);
                            result.setExtractionSuccess(false);
                            result.setExtractionError(e.getMessage());
                            etlSuccess.set(false);
                        }
                        
                        // 在提取阶段同步
                        waitAtBarrier(extractionBarrier, "extraction", sourceId);
                        
                        // 步骤2: 转换阶段
                        if (extractedData != null) {
                            logger.info("Starting transformation for source: {}", sourceId);
                            try {
                                TransformedData transformedData = 
                                    transformer.transform(sourceId, extractedData);
                                transformedDataMap.put(sourceId, transformedData);
                                result.setRecordsTransformed(transformedData.getRecordCount());
                                result.setTransformationSuccess(true);
                                logger.info("Transformed {} records from {}", 
                                          transformedData.getRecordCount(), sourceId);
                                
                                // 收集转换指标
                                metrics.recordTransformation(sourceId, transformedData.getRecordCount());
                            } catch (Exception e) {
                                logger.error("Transformation failed for source: " + sourceId, e);
                                result.setTransformationSuccess(false);
                                result.setTransformationError(e.getMessage());
                                etlSuccess.set(false);
                            }
                        }
                        
                        // 在转换阶段同步
                        waitAtBarrier(transformationBarrier, "transformation", sourceId);
                        
                        // 步骤3: 验证阶段
                        if (transformedDataMap.containsKey(sourceId)) {
                            logger.info("Starting validation for source: {}", sourceId);
                            try {
                                TransformedData transformedData = transformedDataMap.get(sourceId);
                                boolean valid = validator.validateSource(sourceId, transformedData);
                                result.setValidationSuccess(valid);
                                
                                if (!valid) {
                                    logger.error("Validation failed for source: {}", sourceId);
                                    etlSuccess.set(false);
                                } else {
                                    logger.info("Validation passed for source: {}", sourceId);
                                }
                            } catch (Exception e) {
                                logger.error("Validation error for source: " +                        
                                // 步骤3: 验证阶段（续）
                        waitAtBarrier(validationBarrier, "validation", sourceId);

                        // 步骤4: 加载阶段
                        if (etlSuccess.get() && transformedDataMap.containsKey(sourceId)) {
                            logger.info("Starting load for source: {}", sourceId);
                            try {
                                TransformedData transformedData = transformedDataMap.get(sourceId);
                                loader.load(sourceId, transformedData);
                                result.setLoadSuccess(true);
                                logger.info("Loaded {} records to data warehouse from {}", 
                                          transformedData.getRecordCount(), sourceId);
                                
                                // 收集加载指标
                                metrics.recordLoad(sourceId, transformedData.getRecordCount());
                            } catch (Exception e) {
                                logger.error("Load failed for source: " + sourceId, e);
                                result.setLoadSuccess(false);
                                result.setLoadError(e.getMessage());
                                etlSuccess.set(false);
                            }
                        }

                        // 在加载阶段同步
                        waitAtBarrier(loadBarrier, "load", sourceId);
                        
                    } catch (Exception e) {
                        logger.error("Unexpected error in ETL pipeline for source: " + sourceId, e);
                        etlSuccess.set(false);
                    } finally {
                        result.setEndTime(System.currentTimeMillis());
                        sourceResults.add(result);
                    }
                }));
            }

            // 等待所有任务完成
            for (Future<?> future : futures) {
                future.get();
            }

            // 最终处理逻辑
            if (etlSuccess.get()) {
                logger.info("ETL process completed successfully");
                return new ETLResult(request.getJobId(), true, 
                                   "ETL completed successfully", 
                                   sourceResults, 
                                   System.currentTimeMillis() - startTime);
            } else {
                // 执行回滚或补偿操作
                logger.warn("ETL process failed, starting compensation...");
                loader.rollback(request.getJobId());
                return new ETLResult(request.getJobId(), false, 
                                   "ETL failed with errors", 
                                   sourceResults, 
                                   System.currentTimeMillis() - startTime);
            }

        } catch (InterruptedException | ExecutionException e) {
            logger.error("ETL process interrupted", e);
            Thread.currentThread().interrupt();
            return new ETLResult(request.getJobId(), false, 
                               "ETL interrupted: " + e.getMessage(), 
                               sourceResults, 
                               System.currentTimeMillis() - startTime);
        } finally {
            executor.shutdown();
            try {
                if (!executor.awaitTermination(60, TimeUnit.SECONDS)) {
                    executor.shutdownNow();
                }
            } catch (InterruptedException e) {
                executor.shutdownNow();
            }
        }
    }

    private void waitAtBarrier(CyclicBarrier barrier, String phase, String sourceId) {
        try {
            barrier.await();
        } catch (InterruptedException | BrokenBarrierException e) {
            logger.error("Barrier wait failed during {} phase for source: {}", phase, sourceId, e);
            Thread.currentThread().interrupt();
        }
    }

    // 结果类定义
    @Data
    public static class ETLResult {
        private final String jobId;
        private final boolean success;
        private final String message;
        private final List<ETLSourceResult> sourceResults;
        private final long duration;
    }

    @Data
    public static class ETLSourceResult {
        private final String sourceId;
        private long startTime;
        private long endTime;
        private boolean extractionSuccess;
        private String extractionError;
        private int recordsExtracted;
        private boolean transformationSuccess;
        private String transformationError;
        private int recordsTransformed;
        private boolean validationSuccess;
        private boolean loadSuccess;
        private String loadError;
    }
}
```
