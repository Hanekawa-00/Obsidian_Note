好的，同学们！我们继续 NLP 期末冲刺。今天我们来看两个非常实用的 NLP 应用：**问答系统 (Question Answering, QA)** 和 **文本摘要 (Text Summarization)**。这两个技术的目标都是帮助我们更快、更准地从海量文本中获取信息。

---

## 概念名称：问答系统 (Question Answering, QA)

### 应用场景（为什么需要）

*   **要解决什么问题？**
    想象一下，当你想知道“法国的首都是哪里？”时，传统的搜索引擎可能会返回一堆包含“法国”和“首都”的网页链接，你需要自己点进去查找答案。问答系统则旨在**直接、简洁地回答用户用自然语言提出的问题**。它不仅仅是匹配关键词，而是要**理解问题**，并从知识源（如网页、数据库、文档库）中找到或生成**精确的答案**。
    *   **核心挑战：** 从理解用户问题的**意图**，到在庞大的信息中**定位**并**提取/生成**那个简短、准确的答案。

*   **以前怎么做？有什么局限？**
    1.  **信息检索 (Information Retrieval, IR) - 关键词匹配：** 这是传统搜索引擎的核心。用户输入关键词，系统返回包含这些关键词的文档列表，按相关性排序。
        *   **局限性：**
            *   **不直接回答问题：** 用户需要自己阅读文档找答案。
            *   **无法理解问题语义：** 对问题的措辞、隐含意图理解有限。搜索 "Who wrote Hamlet?" 和 "Hamlet author" 可能得到相似结果，但无法直接给出 "William Shakespeare"。
            *   **答案可能分散：** 答案可能分布在文档的不同位置，甚至需要结合多个文档的信息。
    2.  **基于模板/规则的早期 QA 系统：** 针对特定领域（如公司 FAQ），预设问题模板和对应的答案。
        *   **局限性：** 只能回答预设范围和形式的问题，无法处理灵活的自然语言提问，扩展性差。

*   **为什么需要问答系统？**
    *   **获取信息更高效：** 用户希望得到即时、精准的答案，而非文档列表。
    *   **交互更自然：** 允许用户用自然语言提问，就像和人交流一样（如智能音箱、聊天机器人）。
    *   **处理信息过载：** 在海量信息中快速定位关键事实。
    *   **驱动智能应用：** 是智能助手、智能客服、教育机器人等应用的核心能力。

*   **不用它会怎样？**
    *   我们仍然需要花费大量时间在搜索结果中筛选和阅读，才能找到想要的答案。
    *   智能助手无法直接回答我们的事实性问题。
    *   很多需要精准信息支撑的自动化流程难以实现。

### 是什么（概念定义及原理 + 数学直觉）

*   **定义：**
    问答系统是一种信息检索和自然语言处理技术，旨在**自动地用自然语言回答用户用自然语言提出的问题**。系统需要理解问题的含义，并从一个或多个信息源中查找、提取或生成答案。

*   **核心思想与比喻：**
    *   **比喻：从图书管理员到领域专家**
        *   **传统搜索 (IR):** 像一个图书管理员，你问他关于“光合作用”的问题，他给你找来一堆相关的书（文档）。
        *   **问答系统 (QA):** 更像一个生物学专家，你问他“光合作用需要什么条件？”，他直接告诉你“光、水、二氧化碳”。他不仅找到了相关信息，还理解了你的问题并给出了直接的答案。

*   **系统分类 (按不同维度):**
    1.  **按知识来源 (Knowledge Source):**
        *   **开放领域 QA (Open-domain QA):** 答案可能来自互联网上的任何地方（如 Web 文档、维基百科）。挑战巨大，知识源庞杂。
        *   **限定领域 QA (Closed-domain / Domain-specific QA):** 答案限定在特定的文档集合、数据库或知识库中（如某个产品的说明书、公司的内部文档、特定领域的知识图谱）。范围受限，通常更容易获得高精度。
    2.  **按答案类型 (Answer Type):**
        *   **事实型 QA (Factoid QA):** 回答通常是一个或几个词，是人名、地名、日期、数字等事实片段。例如，“珠穆朗玛峰有多高？” -> “8848.86米”。
        *   **列表型 QA (List QA):** 回答是一个实体列表。例如，“写出美国最大的三个城市。” -> “纽约、洛杉矶、芝加哥”。
        *   **是/否 QA (Yes/No QA):** 回答是简单的“是”或“否”。
        *   **定义型 QA (Definition QA):** 回答是对某个术语的定义。例如，“什么是人工智能？”
        *   **段落抽取型 QA (Extractive QA / Reading Comprehension):** 答案是原文中的一个**连续文本片段 (span)**。这是目前研究最多的类型之一。例如，给一段关于爱因斯坦的文章，问“爱因斯坦在哪里出生？”，模型需要从文章中找到并返回“德国乌尔姆”。
        *   **生成式/抽象式 QA (Abstractive QA):** 答案由模型**生成**，可能包含原文中没有的词语，是原文内容的**重新表述或总结**。例如，问“为什么天空是蓝色的？”，模型可能生成一段解释瑞利散射的文字。
    3.  **按交互方式 (Interaction):**
        *   **单轮 QA (Single-turn QA):** 一问一答。
        *   **多轮/对话式 QA (Multi-turn / Conversational QA):** 用户的问题可能依赖于之前的对话历史，需要理解上下文。

*   **数学直觉（重点在理解流程和目标）：**
    *   **核心挑战的数学体现：**
        1.  **问题理解：** 将自然语言问题 $Q$ 转换成一种内部表示（如向量 $\vec{v}_Q$），捕捉其语义和意图。
        2.  **信息定位：** 在巨大的信息源 $S$ 中找到与问题 $Q$ 最相关的部分 $P$ (Passage/Paragraph)。这通常涉及到**相似度计算**。例如，使用向量表示，计算问题向量 $\vec{v}_Q$ 和候选段落向量 $\vec{v}_P$ 的**余弦相似度**：
            $Similarity(Q, P) = \frac{\vec{v}_Q \cdot \vec{v}_P}{||\vec{v}_Q|| \times ||\vec{v}_P||}$
            相似度高的段落被认为更可能包含答案。
        3.  **答案抽取/生成：**
            *   **抽取式:** (比如基于 BERT 的模型) 模型通常需要预测答案在段落 $P$ 中的**起始位置 (start index)** 和**结束位置 (end index)**。模型会为段落中的每个词（token）输出两个概率分布：一个是作为答案起点的概率 $P_{start}(i|Q, P)$，一个是作为答案终点的概率 $P_{end}(j|Q, P)$。目标是找到概率乘积 $P_{start}(i) \times P_{end}(j)$ (且 $j \ge i$) 最大的 $(i, j)$ 对。
                *   **Softmax** 同样在这里发挥作用，将模型内部对每个位置的打分转换成概率。
            *   **生成式:** 通常基于**序列到序列 (Seq2Seq)** 模型，将问题 $Q$（有时也加上相关上下文 $P$）作为输入，生成答案序列 $A$。目标是最大化生成正确答案的概率 $P(A|Q, P)$。

### 怎么做（核心思想/算法步骤 + 关键公式与直观解释）

问答系统的实现方法有很多，从传统的多阶段流程到现代的端到端深度学习模型。

1.  **传统 IR + NLP 流程 (多阶段):**
    *   **核心思想：** 分解问题，逐步筛选信息。
    *   **步骤：**
        1.  **问题分析 (Question Analysis):**
            *   识别问题类型（事实型、列表型、定义型等）。
            *   提取关键词、命名实体。
            *   判断期望的答案类型（人名、地点、日期等）。
        2.  **文档检索 (Document Retrieval):**
            *   使用问题中的关键词（或扩展后的关键词）通过**信息检索 (IR)** 系统（类似搜索引擎）从大规模文档库（如 Web）中召回一批可能相关的文档。
            *   常用技术：TF-IDF, BM25 算法，向量相似度搜索。
        3.  **段落检索/排序 (Passage Retrieval/Ranking):**
            *   将召回的文档切分成段落。
            *   计算每个段落与问题的**相关性分数**（如基于词重叠、TF-IDF、向量相似度）。
            *   对段落进行排序，选择最相关的 Top-K 个段落。
        4.  **答案抽取 (Answer Extraction):**
            *   在排名靠前的段落中，精确定位答案。
            *   可能会用到：命名实体识别 (NER) 来匹配期望的答案类型、依存句法分析来理解句子结构、模式匹配、或者训练一个简单的分类器来判断一个文本片段是否是答案。
    *   **优点：** 流程清晰，易于理解和调试。
    *   **缺点：** 每个阶段的错误会累积；依赖特征工程和规则；对语义理解和复杂推理能力有限。

2.  **基于深度学习的方法 (尤其是抽取式 QA - 阅读理解):**
    *   **核心思想：** 端到端学习。利用深度模型（尤其是预训练模型如 BERT）直接从 (问题, 上下文段落) 对中学习抽取答案。
    *   **代表模型：BERT for QA**
        *   **输入：** 将问题 (Q) 和包含潜在答案的上下文段落 (P) **拼接**成一个特殊的序列输入给 BERT，通常格式为 `[CLS] Question [SEP] Passage [SEP]`。
        *   **模型结构：** 使用预训练好的 BERT 模型。BERT 内部的 Transformer 和 Self-Attention 机制能够深入理解问题和段落之间的语义交互。
        *   **输出层：** 在 BERT 的最后一层输出之上，添加**两个独立的全连接层 + Softmax**：
            1.  一个用于预测**答案起始位置**的概率分布（在段落 P 的每个 token 上）。
            2.  一个用于预测**答案结束位置**的概率分布（也在段落 P 的每个 token 上）。
        *   **训练：** 使用大量 (问题, 段落, 答案起始位置, 答案结束位置) 的标注数据进行训练。目标是让模型预测的起始和结束位置概率在**正确**的位置上尽可能高。使用的损失函数通常是**起始位置的交叉熵损失**和**结束位置的交叉熵损失**的**和**或**平均值**。
            $Loss = CE(P_{start}^{true}, P_{start}^{pred}) + CE(P_{end}^{true}, P_{end}^{pred})$
        *   **预测：** 对于新的 (问题, 段落) 对，模型输出起始和结束位置的概率分布。选择概率乘积 $P_{start}(i) \times P_{end}(j)$ 最大且 $j \ge i$ 的 $(i, j)$ 作为预测的答案 span。
    *   **优点：** 效果显著优于传统方法，能更好地理解语义和上下文，端到端学习简化流程。
    *   **缺点：** 需要大量标注数据（如 SQuAD 数据集），模型复杂、计算量大，可解释性较差。主要适用于答案是原文片段的抽取式任务。

*   **Mermaid 图示：BERT for Extractive QA**
    ```mermaid
    graph TD
        A[Input: Question Q, Passage P] --> B(Format: "[CLS] Q [SEP] P [SEP]");
        B --> C{Pre-trained BERT Model};
        C -- Processes Input --> D[Output Token Embeddings];
        subgraph "Prediction Layers"
            D --> E{Linear + Softmax for Start};
            D --> F{Linear + Softmax for End};
            E --> G[Start Probabilities P_start(i)];
            F --> H[End Probabilities P_end(j)];
        end
        G & H --> I{Find (i, j) maximizing P_start(i) * P_end(j)};
        I --> J[Output: Answer Span from index i to j in P];

        style C fill:#ccf,stroke:#333,stroke-width:2px
    ```

### 常见考试问题（如何应对）

1.  **Q: 什么是问答系统 (QA)？相比传统信息检索 (IR)，它的主要目标有什么不同？**
    *   **A (思路):**
        *   QA 定义：自动用自然语言回答用户自然语言问题的系统。
        *   目标不同：IR 的目标是返回**相关的文档列表**，用户自己找答案；QA 的目标是**直接返回问题的精确答案**。QA 需要更深层次的**问题理解**和**答案定位/生成**。

2.  **Q: 问答系统可以按哪些维度分类？请至少说出两种分类方式及其类别。**
    *   **A (思路):**
        *   按知识来源：开放领域 vs 限定领域。
        *   按答案类型：事实型、列表型、是/否、定义型、抽取式、生成式。
        *   (可选) 按交互方式：单轮 vs 多轮/对话式。

3.  **Q: 解释抽取式问答 (Extractive QA) 和生成式问答 (Abstractive QA) 的区别。**
    *   **A (思路):**
        *   **抽取式:** 答案是**直接从**提供的上下文文本中**抽取**出来的一个连续片段 (span)。答案中的词语都来自原文。
        *   **生成式:** 答案由模型**生成**，可能包含原文中没有的词语，是对原文信息的**改写、综合或推理**。

4.  **Q: 在基于 BERT 的抽取式问答模型中，模型通常需要预测什么来确定答案？（说明基本思路）**
    *   **A (思路):**
        *   模型需要预测答案在给定上下文段落中的**起始位置 (start index)** 和**结束位置 (end index)**。
        *   基本思路：BERT 处理拼接后的 (问题, 段落) 输入，最后通过两个独立的 Softmax 层，分别输出段落中每个 token 作为答案**起点**的概率和作为答案**终点**的概率。选择概率乘积最大的合法 (end >= start) 起止位置对。

5.  **Q: 传统 QA 系统通常包含哪些主要阶段？（简述）**
    *   **A (思路):**
        1.  问题分析：理解问题类型、关键词、期望答案类型。
        2.  文档检索：用 IR 技术召回相关文档。
        3.  段落检索/排序：筛选并排序相关段落。
        4.  答案抽取：在段落中精确定位答案。

### 真实任务案例（实际应用演示）

*   **智能客服机器人回答常见问题:**
    *   **场景:** 用户在银行 App 或网站上提问：“如何修改预留手机号？”
    *   **QA 应用:**
        1.  **系统类型:** 通常是**限定领域 QA**（知识库是银行的业务文档、FAQ）。答案可能是**抽取式**（从标准流程文档中提取步骤）或**生成式/模板式**（生成友好的、包含关键信息的回答）。
        2.  **流程 (可能):**
            *   **问题理解:** 系统识别出用户的意图是“修改手机号”，可能涉及的实体是“手机号”。
            *   **信息检索:** 在银行的知识库中搜索与“修改手机号”相关的文档或 FAQ 条目。
            *   **答案处理:**
                *   **抽取式:** 找到描述修改流程的段落，如“请携带身份证前往任意网点办理，或登录手机银行App在‘设置-个人信息-手机号管理’中修改。”，模型提取这段文字作为答案。
                *   **生成式/模板:** 系统检索到关键信息（办理渠道：网点/App，所需材料：身份证），然后套用模板生成回答：“您好！您可以通过以下方式修改预留手机号：1. 前往我行任意网点办理，请携带有效身份证件。2. 登录手机银行App，在‘设置-个人信息-手机号管理’页面进行修改。”
    *   **效果:** 快速、准确地解答用户的常见问题，减轻人工客服压力，提高用户满意度。

---

## 概念名称：文本摘要 (Text Summarization)

### 应用场景（为什么需要）

*   **要解决什么问题？**
    我们每天面对的信息量是爆炸性的：长篇新闻报道、冗长的研究论文、大量的会议记录、电子邮件线索等。文本摘要的目标就是**自动地将一篇（或多篇）长文本缩减成一篇短文本**，这篇短文本需要**保留原文的核心内容和关键信息**。
    *   **核心挑战：** 识别出原文中哪些信息是重要的，并将这些信息**简洁、连贯**地呈现出来。

*   **以前怎么做？有什么局限？**
    1.  **人工摘要：** 由人阅读原文并撰写摘要。
        *   **局限性：** 耗时、成本高、主观性（不同人摘要可能不同），无法规模化处理。
    2.  **简单的启发式方法：** 比如只提取文章的第一段或每段的第一句话。
        *   **局限性：** 非常粗糙，可能丢失重要信息（关键点可能在文章中间或结尾），生成的摘要可能不连贯。

*   **为什么需要（自动）文本摘要？**
    *   **节省时间：** 快速了解大量文本的主要内容，无需阅读全文。
    *   **提高效率：** 帮助研究人员快速筛选文献，帮助管理人员快速把握报告要点。
    *   **信息概览：** 在新闻聚合、搜索引擎结果中提供文章摘要。
    *   **辅助写作：** 自动生成文档摘要或会议纪要。

*   **不用它会怎样？**
    *   我们需要花费大量时间阅读才能获取信息，效率低下。
    *   难以快速把握大量文档的核心内容。
    *   信息过载问题更加严重。

### 是什么（概念定义及原理 + 数学直觉）

*   **定义：**
    文本摘要是利用计算机自动地将一个或多个文本（源文本）转换成一个更短的文本（摘要）的过程，摘要需要准确地反映源文本的主要思想和关键信息。

*   **核心思想与比喻：**
    *   **比喻：写读书笔记 vs 做重点标记**
        *   **写读书笔记 (类似 Abstractive):** 你读完一本书，用**自己的话**把书的核心思想、主要情节、关键论点总结出来。你的总结里可能用了书中没有的词语，但表达了同样的意思。
        *   **做重点标记 (类似 Extractive):** 你读一本书，拿出荧光笔，把书中你认为**最重要的句子或段落直接划出来**。最后把所有划线的部分放在一起，就成了一个“摘要”。

*   **系统分类:**
    1.  **按输入文档数量:**
        *   **单文档摘要 (Single-document Summarization):** 对一篇文档生成摘要。
        *   **多文档摘要 (Multi-document Summarization):** 对关于同一主题的多篇文档生成一个综合性摘要。更具挑战性，需要处理信息冗余和整合不同来源的信息。
    2.  **按输出类型 (最重要分类):**
        *   **抽取式摘要 (Extractive Summarization):**
            *   **方法：** 从原文中**选择**一些**重要**的句子或短语，然后将它们**组合**起来形成摘要。摘要完全由原文的片段构成。
            *   **优点：** 实现相对简单，保证语法正确性（因为是原文句子），事实一致性较好（不会“编造”信息）。
            *   **缺点：** 可能缺乏连贯性（句子之间衔接生硬），可能存在冗余，无法进行信息融合或改写。
        *   **生成式/抽象式摘要 (Abstractive Summarization):**
            *   **方法：** 模型需要**理解**原文的内容，然后**用自己的方式 (生成新的词语和句子)** 来重新表达核心信息。摘要中可能包含原文没有的词语。
            *   **优点：** 摘要通常更**流畅、连贯、简洁**，能更好地进行信息融合和改写，更像人写的摘要。
            *   **缺点：** 实现更复杂（通常需要 Seq2Seq 模型），容易出现**事实错误**（模型可能“幻觉”出不准确的信息），语法错误的风险也更高。

*   **数学直觉（重点在理解方法目标）：**
    *   **抽取式摘要：**
        *   **核心是“打分”：** 需要一个方法来评估原文中每个句子（或单元）的**重要性分数 (Importance Score)**。
        *   **打分依据（数学体现）：**
            *   **位置特征：** 句子在文中的位置（如句子的序号）。
            *   **词频/TF-IDF 特征：** 句子中包含高 TF-IDF 值（关键词）的数量或总权重。
            *   **向量表示与相似度：** 将句子表示为向量 $\vec{v}_S$。
                *   与文档中心相似度：计算句子向量与整个文档向量（如所有句子向量的平均值 $\vec{v}_D$) 的**余弦相似度** $Similarity(S, D)$。越接近中心的句子可能越重要。
                *   句子间相似度 (用于图模型如 TextRank): 计算句子 $S_i$ 和 $S_j$ 的相似度 $Similarity(S_i, S_j)$。一个句子如果与很多其他（重要的）句子相似，那么它也可能很重要。TextRank 算法类似 PageRank，通过迭代更新句子的分数，分数会从重要的句子“流向”与之相似的句子。
        *   **选择：** 选择分数最高的 Top-K 个句子构成摘要。
    *   **生成式摘要：**
        *   **核心是“序列生成”：** 通常使用**序列到序列 (Sequence-to-Sequence, Seq2Seq)** 模型。
        *   **模型结构：**
            *   **编码器 (Encoder):** 读取源文档 $X$，将其编码成一个（或一系列）包含文档信息的向量表示 $H$。
            *   **解码器 (Decoder):** 基于编码器的输出 $H$ 和已经生成的部分摘要 $y_{<t}$，一步步生成摘要中的下一个词 $y_t$。目标是最大化生成参考摘要（或高质量摘要）的概率 $P(Y|X)$。
            *   $P(y_t | H, y_{<t})$ 通常通过 **Softmax** 在词汇表上计算得到。
        *   **训练：** 需要大量的 (原文, 摘要) 对进行监督学习。损失函数通常是**交叉熵损失**，衡量生成的摘要与参考摘要之间的差异。

### 怎么做（核心思想/算法步骤 + 关键公式与直观解释）

1.  **抽取式摘要方法:**
    *   **核心思想：** 给句子打分，选高分句子。
    *   **步骤：**
        1.  **文本预处理：** 将文档分割成句子。可能需要分词、去停用词等。
        2.  **句子表示：** 将每个句子转换成向量（如 TF-IDF 向量、句子嵌入向量）。
        3.  **句子打分：** 使用某种策略计算每个句子的重要性分数。
            *   **简单方法：**
                *   **Lead-based:** 选择前 N 个句子（新闻常用）。
                *   **TF-IDF based:** 计算句子中所有词的 TF-IDF 值之和。
            *   **基于图的方法 (如 TextRank):**
                a.  构建一个图，每个句子是一个节点。
                b.  计算任意两个句子之间的**相似度**（如余弦相似度），作为边的权重。
                c.  运行类似 PageRank 的算法，迭代计算每个节点（句子）的重要性分数。得分高的句子是那些与很多其他（重要的）句子相似的句子。
                d.  **TextRank 迭代公式直观理解：** 一个句子的分数 = (基础分数) + (从指向它的其他句子“流入”的分数总和)。流入的分数与指向它的句子的分数、以及它们之间的相似度有关。
        4.  **句子选择：** 选择得分最高的 Top-K 个句子（K 由期望的摘要长度决定）。
        5.  **摘要后处理：** 可能需要按原文顺序排列选出的句子，或者进行一些简单的连贯性处理。
    *   **优点/缺点:** 见上文。

2.  **生成式摘要方法 (Seq2Seq):**
    *   **核心思想：** 理解原文，重新写摘要。
    *   **模型架构：** Encoder-Decoder (通常基于 RNN/LSTM 或 Transformer)。
        *   **Encoder:** 读入源文档 $X=(x_1, ..., x_m)$，生成隐藏状态序列 $H=(h_1, ..., h_m)$ 或一个最终的上下文向量 $C$。
        *   **Decoder:** 在每个时间步 $t$，根据 Encoder 的信息 $H$ (或 $C$) 和之前生成的词 $y_{<t}$，预测下一个词 $y_t$ 的概率分布。
            $P(y_t | H, y_{<t}) = \text{Decoder}(H, y_{<t})$ (通常最后是 Softmax)
        *   **Attention 机制 (重要！):** 为了让 Decoder 在生成每个词时能**关注**到 Encoder 不同部分的信息（原文中与当前生成词相关的部分），通常会加入 Attention 机制。Decoder 在生成 $y_t$ 时，会计算一个权重分布 $\alpha_t$ 在 Encoder 的隐藏状态 $H$ 上，表示此时应该“注意”原文的哪些部分。然后生成 $y_t$ 时会用到这个加权的上下文信息。
            *   **直观比喻：** 就像你在写总结时，写到某个点会回头看看原文中对应的段落。Attention 让模型也能做到类似的事情。
    *   **训练：** 使用 (原文, 参考摘要) 对进行监督训练，最小化生成摘要与参考摘要之间的交叉熵损失。
    *   **预测/生成：** 使用**集束搜索 (Beam Search)** 等解码策略来生成最终的摘要文本，而不是简单地在每一步都选择概率最高的词（贪心搜索）。Beam Search 会保留 K 个最可能的候选序列，提高生成质量。
    *   **优点/缺点:** 见上文。

*   **Mermaid 图示：Extractive vs. Abstractive Summarization**
    ```mermaid
    graph TD
        A[Original Document] --> B{Method?};

        subgraph Extractive Summarization
            direction LR
            B -- Extractive --> C(Split into Sentences);
            C --> D(Represent Sentences as Vectors);
            D --> E(Score Sentences: TF-IDF, TextRank, etc.);
            E --> F(Select Top-K Sentences);
            F --> G[Combine Sentences];
        end

        subgraph Abstractive Summarization (Seq2Seq)
            direction LR
            B -- Abstractive --> H{Encoder};
            H -- Context Representation --> I{Decoder with Attention};
            I -- Generates Word by Word --> J[Generated Summary];
        end

        G --> K((Output: Extractive Summary));
        J --> L((Output: Abstractive Summary));

        style E fill:#f9f,stroke:#333
        style I fill:#ccf,stroke:#333
    ```

### 评价指标 (Evaluation Metrics)

摘要不像分类有明确的对错，评价起来更困难。常用**基于 N-gram 重叠度**的自动评价指标 **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**。

*   **核心思想：** 比较**模型生成的摘要 (Candidate)** 与一个或多个**人工写的参考摘要 (Reference)** 之间，有多少**共现的 N-gram** (词序列)。
*   **常用 ROUGE 指标：**
    *   **ROUGE-N:** 计算 N-gram (通常 N=1, 2) 的重叠度。
        *   **ROUGE-1:** 衡量**单个词 (unigram)** 的重叠程度（类似 Recall）。
        *   **ROUGE-2:** 衡量**两个词组成的 bigram** 的重叠程度。
        *   **公式 (以 ROUGE-1 Recall 为例):**
            $ROUGE-1_{Recall} = \frac{\sum_{S \in \text{Refs}} \sum_{gram_1 \in S} \text{Count}_{\text{match}}(gram_1)}{\sum_{S \in \text{Refs}} \sum_{gram_1 \in S} \text{Count}(gram_1)}$
            *   **分子：** 在所有参考摘要中出现的、且也在模型摘要中出现的 unigram 的总数。
            *   **分母：** 所有参考摘要中 unigram 的总数。
            *   **直观含义：** 参考摘要中有多少比例的词语，在模型生成的摘要中也出现了？
        *   通常也计算 Precision 和 F1-score。
    *   **ROUGE-L:** 计算**最长公共子序列 (Longest Common Subsequence, LCS)** 的重叠度。考虑了句子的顺序信息，但不要求连续。
        *   **直观含义：** 模型摘要和参考摘要在句子结构和主要内容顺序上的相似程度。
*   **优点：** 计算简单、自动化、与人工评价有一定相关性。
*   **缺点：**
    *   **只看表面词语重叠：** 无法衡量语义相似性（同义词、不同表达方式会被忽略）。
    *   **不关心语法和流畅性：** ROUGE 分数高不代表摘要一定通顺可读。
    *   **对抽象式摘要可能不公平：** 好的抽象式摘要可能用词与原文/参考摘要不同，导致 ROUGE 分数偏低。
*   **人工评价:** 仍然是评价摘要质量（如信息量、流畅性、连贯性、事实准确性）的金标准，但成本高。

### 常见考试问题（如何应对）

1.  **Q: 什么是文本摘要？它的主要目标是什么？**
    *   **A (思路):**
        *   定义：自动将长文本缩减为短文本，保留核心内容。
        *   目标：节省用户阅读时间，快速提供文本关键信息，同时保持简洁和连贯。

2.  **Q: 解释抽取式摘要 (Extractive Summarization) 和生成式摘要 (Abstractive Summarization) 的主要区别及其优缺点。**
    *   **A (思路):**
        *   **抽取式:**
            *   区别：选择原文句子/短语组合。
            *   优点：简单、语法好、事实一致。
            *   缺点：可能不连贯、冗余。
        *   **生成式:**
            *   区别：生成新句子表达核心内容。
            *   优点：流畅、简洁、能融合信息。
            *   缺点：复杂、可能事实错误、语法风险。

3.  **Q: 抽取式摘要常用的句子重要性评分方法有哪些？（至少列举两种思路）**
    *   **A (思路):**
        *   基于位置 (Lead-based)。
        *   基于关键词/TF-IDF。
        *   基于与文档中心的相似度。
        *   基于图模型 (TextRank - 句子间相似度)。

4.  **Q: 生成式摘要通常使用什么模型架构？简述其基本工作原理。**
    *   **A (思路):**
        *   架构：**序列到序列 (Sequence-to-Sequence, Seq2Seq)** 模型（Encoder-Decoder 结构）。
        *   原理：Encoder 读取原文生成表示，Decoder 基于该表示逐步生成摘要词语。通常会用到 Attention 机制让 Decoder 关注原文相关部分。

5.  **Q: ROUGE 是用来评价什么的？ROUGE-1 和 ROUGE-L 大致衡量了什么？（直观解释）**
    *   **A (思路):**
        *   评价：自动评价文本摘要质量，通过比较生成摘要和参考摘要的 N-gram 重叠度。
        *   ROUGE-1：衡量**单个词**的重叠程度（词汇覆盖率）。
        *   ROUGE-L：衡量**最长公共子序列**的重叠程度（句子结构和顺序相似性）。

### 真实任务案例（实际应用演示）

*   **新闻 App 的文章摘要:**
    *   **场景:** 用户在手机上看新闻，时间有限，希望快速了解新闻大概。
    *   **摘要应用:**
        1.  **系统类型:** 通常是**单文档摘要**。可能是**抽取式**（实现简单快速），也可能是**生成式**（摘要更自然）。
        2.  **流程:**
            *   **抽取式:** 系统加载一篇新闻报道，对其句子进行打分（比如结合位置、TF-IDF、TextRank），选出得分最高的 2-3 句话，按原文顺序排列，展示在新闻标题下方。
            *   **生成式:** 使用预训练好的 Seq2Seq 模型（如基于 BART, T5 等），输入完整的新闻报道，模型直接生成一段简短的摘要文本。
    *   **效果:** 用户无需点击进入全文，就能快速了解新闻要点，决定是否要深入阅读，大大提高了信息获取效率。

### 其它相关内容

*   **相关前置/后置概念:**
    *   **前置:** 信息检索 (IR), 文本表示 (TF-IDF, Embeddings), 序列到序列模型 (Seq2Seq), Attention 机制, PageRank (TextRank 的基础)。
    *   **后置/相关:** 自然语言生成 (NLG), 机器翻译 (共享 Seq2Seq 技术), 对话系统 (可能需要摘要能力)。
*   **挑战:**
    *   **评价指标的局限性:** ROUGE 无法完全反映摘要质量。
    *   **事实一致性 (Factual Consistency):** 特别是生成式摘要，如何确保生成的内容与原文事实一致。
    *   **连贯性与流畅性:** 如何让摘要读起来自然通顺。
    *   **处理长文档:** Seq2Seq 模型对输入长度有限制，如何有效处理非常长的文档。
    *   **多文档摘要的挑战:** 信息冗余、观点冲突、时间线索处理。
*   **发展趋势:**
    *   **预训练模型 (PLMs) 的应用:** BART, T5, Pegasus 等专门为生成任务设计的预训练模型极大提升了摘要性能。
    *   **可控摘要 (Controllable Summarization):** 生成满足特定要求（如指定长度、包含特定关键词、侧重特定方面）的摘要。
    *   **结合知识图谱:** 利用外部知识提高摘要的准确性和信息量。
    *   **改进评价指标:** 探索更能反映语义和事实一致性的自动评价方法。

---

问答系统和文本摘要都是旨在帮助我们应对信息爆炸的实用技术。理解它们的基本概念、分类、核心方法（尤其是抽取式 vs 生成式）以及评价方式，是掌握现代 NLP 应用的重要一环。记住，QA 追求“精准答案”，而 Summarization 追求“简练概括”。